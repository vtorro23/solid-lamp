\chapter{Dualidad}
\section{Repaso del espacio dual}
Sea $\displaystyle V $ un $\displaystyle \K  $-espacio vectorial. Decíamos que $\displaystyle V^{*}=\Hom\left(V, \K\right) $ es el \textbf{espacio dual}, donde $\displaystyle V^{*} $ también es un $\displaystyle \K $-espacio vectorial. En efecto, si $\displaystyle \phi, \psi \in \Hom\left(V, \K\right) $, tenemos que 
\[\left(\phi + \psi\right)\left(v\right) : = \phi\left(v\right) + \psi\left(v\right), \; \forall v \in V .\]
Análogamente, si $\displaystyle \lambda \in \K $ y $\displaystyle \phi \in \Hom\left(V, \K\right) $ tenemos que 
\[\left(\lambda \phi\right)\left(v\right) : = \lambda\left(\phi\left(v\right)\right), \; \forall v \in V .\]
Sea $\displaystyle \mathcal{B} = \left\{ v_{1}, \ldots, v_{n}\right\}  $ una base de $\displaystyle V $. Definimos $\displaystyle \phi_{i} : V \to \K $ de forma que 
\[\phi_{i}\left(v_{j}\right) = 
\begin{cases}
1, \; i= j \\ 
0, \; i \neq j
\end{cases}
, \; \forall j = 1, \ldots, n.\]
Veamos que $\displaystyle \mathcal{B}^{*} = \left\{ \phi_{1}, \ldots, \phi_{n}\right\}  $ es una base de $\displaystyle V^{*} $. Sea $\displaystyle \phi \in V^{*} $ y sea $\displaystyle u = \left(x_{1}, \ldots, x_{n}\right)_{\mathcal{B}} \in V $. Tenemos que 
\[\phi\left(u\right) = \phi\left(x_{1}v_{1} + \cdots + x_{n}v_{n}\right) = x_{1}\phi\left(v_{1}\right) + \cdots + x_{n}\phi\left(v_{n}\right) .\]
Por otro lado, tenemos que 
\[
\begin{split}
	\left(\phi\left(v_{1}\right)\phi_{1} + \cdots + \phi\left(v_{n}\right)\phi_{n}\right)\left(u\right) = & \phi\left(v_{1}\right)\phi_{1}\left(u\right) + \cdots + \phi\left(v_{n}\right)\phi_{n}\left(u\right) \\
	= & \phi\left(v_{1}\right)\phi_{1}\left(x_{1}v_{1} + \cdots + x_{n}v_{n}\right) + \cdots + \phi\left(v_{n}\right)\phi_{n}\left(x_{1}v_{1} + \cdots + x_{n}v_{n}\right) \\
	= & \phi\left(v_{1}\right)\sum^{n}_{i = 1}x_{i}\phi_{1}\left(v_{i}\right) + \cdots + \phi\left(v_{n}\right)\sum^{n}_{i = 1}x_{i}\phi_{n}\left(v_{i}\right) \\
	= & x_{1}\phi\left(v_{1}\right) + \cdots + x_{n}\phi\left(v_{n}\right) .
\end{split}
\]
Veamos que $\displaystyle \mathcal{B}^{*} $ son linealmente independientes. Supongamos que 
\[0 = \lambda_{1}\phi_{1} + \cdots + \lambda_{n}\phi_{n} .\]
Tenemos entonces que 
\[0 = \lambda_{1}\phi_{1}\left(v_{i}\right) + \cdots + \lambda_{n}\phi_{n}\left(v_{i}\right) = \lambda_{i} .\]
Por tanto, tenemos que $\displaystyle \lambda_{i} = 0 $, $\displaystyle \forall i = 1, \ldots, n $ y en consecuencia son linealmente independientes. 
\begin{colorary}
Si $\displaystyle \dim_{\K}V < \infty $, entonces $\displaystyle \dim_{\K}V = \dim_{\K}V^{*} $ \footnote{Si la dimensión es infinita también es cierto pero no nos vale la demostración anterior.}. 
\end{colorary}
Supongamos que $\displaystyle \dim_{\K}V < \infty $ y veamos que hay un isomorfismo canónico entre $\displaystyle V $ y $\displaystyle V^{**} = \left(V^{*}\right)^{*} = \Hom\left(V^{*}, \K\right) $. Este viene dado por la función 
\[\ev : V \to V^{**} : u \to \ev_{u} ,\quad \ev_{u} : V^{*} \to \K : \phi \to \ev_{u}\left(\phi\right) = \phi\left(u\right).\]
Veamos que es un isomorfismo:
\[\ev_{u_{1}+u_{2}}\left(\phi\right) = \phi\left(u_{1} + u_{2}\right) = \phi\left(u_{1}\right) + \phi\left(u_{2}\right) = \ev_{u_{1}}\left(\phi\right) + \ev_{u_{2}}\left(\phi\right), \; \forall \phi \in V^{*} .\]
\[ev_{\lambda u}\left(\phi\right) = \phi\left(\lambda\right) = \lambda \phi\left(u\right) = \lambda \ev_{u}\left(\phi\right), \; \forall \phi \in V^{*} .\]
Así, hemos visto que $\displaystyle \ev $ es lineal. Veamos ahora que $\displaystyle \ev $ es inyectiva. 
\[
\begin{split}
	\ev_{u} = 0 \iff & \ev_{u}\left(\phi\right) = 0, \; \forall \phi \in V^{*} \iff \phi\left(u\right) = 0, \; \forall \phi \in V^{*} \iff \phi_{i}\left(u\right) = 0, \; \forall \phi_{i}\in \mathcal{B}^{*} \\
	\iff & u = 0 \iff $\displaystyle \Ker\left(\ev\right) = \left\{ 0\right\}  $ .
\end{split}
\]
Como $\displaystyle \dim_{\K}V = \dim_{\K}V^{*} = \dim_{\K}\left(V^{**}\right) < \infty $, con ver que es inyectiva hemos visto que es biyectiva y por tanto es un isomorfismo. Abusando de la notación, identificamos $\displaystyle V $ con $\displaystyle V^{**} $ mediante $\displaystyle u = \ev_{u} $. \\ \\ 
Dado $\displaystyle U \in \mathcal{L}\left(V\right) $, podemos definir el \textbf{ortogonal} de $\displaystyle U $ de la forma
\[U^{\perp } = \left\{ \phi \in V^{*} \; : \; \phi\left(u\right) = 0, \; \forall u \in U\right\}  .\]
\begin{prop}
Se cumple, 
\begin{enumerate}
\item $\displaystyle U^{\perp } $ es un $\displaystyle \K $-subespacio vectorial de $\displaystyle V^{*} $. 
\item Si $\displaystyle U \subset W $, entonces $\displaystyle W^{\perp } \subset U^{\perp } $. 
\item $\displaystyle \dim_{\K}U^{\perp } = \dim_{\K}V - \dim_{\K}U $. 
\item $\displaystyle V^{\perp } = \left\{ 0\right\}  $ y $\displaystyle \left\{ 0\right\} ^{\perp } = V^{*} $.
\end{enumerate}
\end{prop}
\begin{proof}
\begin{enumerate}
\item Claramente $\displaystyle U^{\perp } \neq \emptyset $ puesto que $\displaystyle 0 \in U^{\perp } $. Ahora, sean $\displaystyle \phi_{1}, \phi_{2} \in U^{\perp } $ y $\displaystyle u \in U $, 
	\[\left(\phi_{1} + \phi_{2}\right)\left(u\right) =\phi_{1}\left(u\right) + \phi_{2}\left(u\right) = 0 \Rightarrow \phi_{1} + \phi_{2} \in U^{\perp } .\]
	Además, sea $\displaystyle \phi \in U^{\perp } $, $\displaystyle \lambda \in \K $ y $\displaystyle u \in U $,
	\[\left(\lambda\phi\right)\left(u\right) = \lambda\left(\phi\left(u\right)\right) = \lambda \cdot 0 = 0 \Rightarrow \lambda \phi \in U^{\perp } .\]
\item Sea $\displaystyle u \in U \subset W $. Si $\displaystyle \phi \in W^{\perp } $ tenemos que $\displaystyle \phi\left(u\right) = 0 $, $\displaystyle \forall u \in U \subset W $, por lo que $\displaystyle \phi \in U^{\perp } $ y en consecuencia $\displaystyle W^{\perp }\subset U^{\perp } $. 
\item Sea $\displaystyle \dim_{\K}U = k $ y $\displaystyle \dim_{\K}V = n $. Sea $\displaystyle \left\{ u_{1}, \ldots, u_{k}\right\}  $ una base de $\displaystyle U $ y la ampliamos a $\displaystyle \left\{ u_{1}, \ldots, u_{n}\right\}  $ base de $\displaystyle V $. Sea $\displaystyle \mathcal{B}^{*} = \left\{ \phi_{1}, \ldots, \phi_{n}\right\}  $ la base dual de la anterior. Tenemos que $\displaystyle \phi_{k+1}, \ldots, \phi_{n} \in U^{\perp } $, puesto que $\displaystyle \forall u = \lambda_{1}u_{1} + \cdots + \lambda_{k}u_{k} \in U $ tenemos que
	\[\forall j > k, \; \phi_{j}\left(u\right) = \lambda_{1}\phi_{j}\left(u_{1}\right) + \cdots + \lambda_{k}\phi_{j}\left(u_{k}\right) = 0 .\]
	Tenemos que $\displaystyle \phi_{k+1}, \ldots, \phi_{n} $ son linealmente independientes por ser parte de una base. Veamos que generan $\displaystyle U^{\perp } $. Sea $\displaystyle \phi \in U^{\perp } $. Como $\displaystyle \mathcal{B}^{*} $ es base de $\displaystyle V^{*} $, tenemos que 
	\[\phi = a_{1}\phi_{1} + \cdots + a_{n}\phi_{n} .\]
	Además, tenemos que
	\[
	\begin{cases}
	\phi\left(u_{i}\right) = a_{1}\phi_{1}\left(u_{i}\right) + \cdots + a_{n}\phi_{n}\left(u_{i}\right) = a_{i} \\ 
	\phi\left(u_{i}\right) = 0
	\end{cases}
	, \; \forall i= 1, \ldots, k.\]
Por tanto, tenemos que $\displaystyle a_{i} = 0 $, $\displaystyle \forall i = 1, \ldots, k $, por lo que $\displaystyle \phi = a_{k+1}\phi_{k+1} + \cdots + a_{n}\phi_{n} $. 
\item Es fácil ver que $\displaystyle \dim_{\K}V^{*} = 0 $, por lo que $\displaystyle V^{*} = \left\{ 0\right\}  $. Análogamente tenemos que $\displaystyle \dim \left\{ 0\right\} ^{\perp} = \dim_{\K}V  $, así tenemos que $\displaystyle \left\{ 0\right\} ^{\perp} = V^{*} $.
\end{enumerate}
\end{proof}
\begin{prop}
Sea $\displaystyle V $ un $\displaystyle \K $-espacio vectorial con $\displaystyle \dim_{\K}V < \infty $ y $\displaystyle U, W \in \mathcal{L}\left(V\right) $. 
\begin{enumerate}
\item $\displaystyle \left(U^{\perp }\right)^{\perp } = U $ \footnote{Este igual no es estricto puesto que $\displaystyle \left(U^{\perp }\right)^{\perp } \subset V^{**} $, realmente estamos diciendo que $\displaystyle \left(U^{\perp }\right)^{\perp } = \ev\left(U\right) $.}.
\item $\displaystyle \left(U \cap W\right)^{\perp } = U^{\perp } + W^{\perp } $. 
\item $\displaystyle \left(U + W\right)^{\perp } = U^{\perp } \cap W^{\perp } $. 
\item Si $\displaystyle V = U \oplus W $, entonces $\displaystyle V^{*} = U^{\perp }\oplus W^{\perp } $.
\end{enumerate}
\end{prop}
\begin{proof}
\begin{enumerate}
	\item Recordamos que $\displaystyle U^{\perp } = \left\{ \phi \in V^{*} \; : \; \phi\left(u\right) = 0, \; \forall u \in U\right\}  $. Así, tenemos que 
		\[\left(U^{\perp }\right)^{\perp } = \left\{ \ev_{v} \in V^{**} \; : \; \ev_{v}\left(\phi\right) = 0, \; \forall \phi \in U^{\perp }\right\} = \left\{ v \; : \; \phi\left(v\right) = 0, \; \forall \phi \in U^{\perp }\right\} = \ev\left(U\right)  .\]
	\item Tenemos que $\displaystyle U \cap W \subset U, W$, por lo que $\displaystyle U^{\perp } \subset \left(U \cap W \right)^{\perp } $ y $\displaystyle W^{\perp } \subset \left(U \cap W\right)^{\perp } $. Por tanto, tenemos que $\displaystyle U^{\perp } + W^{\perp } \subset \left(U \cap W\right)^{\perp } $. Por otro lado, tenemos que 
		\[U \cap W = \left(\left(U \cap W\right)^{\perp }\right)^{\perp } \subset \left(U^{\perp } + W^{\perp }\right)^{\perp } \subset \left(U^{\perp }\right)^{\perp } \cap \left(W^{\perp }\right)^{\perp } = U \cap W .\]
		Por tanto, debe ser que todos los contenidos son igualdades, en particular, $\displaystyle U \cap W = \left(U^{\perp } + W^{\perp }\right)^{\perp } $. Así, obtenemos que $\displaystyle \left(U \cap W\right)^{\perp } = \left(\left(U^{\perp } + W^{\perp }\right)^{\perp }\right)^{\perp } = U^{\perp } + W^{\perp } $.	
	\item Como $\displaystyle U \subset U + W $ y $\displaystyle W \subset U + W $, tenemos que $\displaystyle \left(U + W\right)^{\perp } \subset U^{\perp }, W^{\perp } $, por lo que $\displaystyle \left(U+W\right)^{\perp } \subset U^{\perp }\cap W^{\perp } $. Tenemos que 
		\[U + W = \left(\left(U + W\right)^{\perp }\right)^{\perp } \supset \left(U^{\perp } \cap W^{\perp }\right)^{\perp }\supset \left(U^{\perp }\right)^{\perp } + \left(W^{\perp }\right)^{\perp } = U + W .\]
	Al igual que en \textbf{(2)}, tenemos que $\displaystyle U + W = \left(U^{\perp }\cap W^{\perp }\right)^{\perp } $, por lo que $\displaystyle \left(U + W\right)^{\perp } = U^{\perp }\cap W^{\perp } $.
\item Consideremos $\displaystyle V = U \oplus W $, es decir, $\displaystyle V = U + W $ y $\displaystyle U \cap W = \left\{ 0\right\}  $. Así, tenemos que $\displaystyle V^{\perp } = U^{\perp }\cap W^{\perp } = \left\{ 0\right\}  $ y $\displaystyle \left\{ 0\right\} ^{\perp } = U^{\perp } + W^{\perp } = V^{*} $. 
\end{enumerate}
\end{proof}
\begin{colorary}
La aplicación 
\[\perp : \mathcal{L}\left(V\right) \to \mathcal{L}\left(V^{*}\right) : U \to U^{\perp } ,\]
es una biyección con sí misma como inversa. Además, cambia $\displaystyle \subset  $ por $\displaystyle \supset  $, y $\displaystyle +  $ por $\displaystyle \cap  $ y viceversa.
\end{colorary}
\section{Dualidad en espacios proyectivos}
Dado un $\displaystyle \K $-espacio vectorial $\displaystyle V $, tenemos que hay una biyección entre las variedades de $\displaystyle \mathbb{P}\left(V\right) $ y los subespacios de $\displaystyle V $. También tenemos una biyección entre los subespacios de $\displaystyle V $ y subespacios de $\displaystyle V^{*} $. En particular
\[ \left\{ X \subset \mathbb{P}\left(V\right) \; : \; X \; \text{variedad}\right\} \leftrightarrow \left\{ X \subset \mathbb{P}\left(V^{*}\right) \; : \; X \; \text{variedad}\right\}  .\]
En efecto, podemos considerar la aplicación $\displaystyle X \to \mathbb{P}\left(\left(\hat{X}\right)^{\perp }\right) $. 
\begin{notation}
Denotamos $\displaystyle X^{*} := \mathbb{P}\left(\left(\hat{X}\right)^{\perp }\right) $. 
\end{notation}
Tenemos que se cumplen las mismas propiedades que hemos demostrado anteriormente para subespacios vectoriales. 
\begin{lema}
Si $\displaystyle \dim\mathbb{P}\left(V\right) = n < \infty $, entonces $\displaystyle \dim X^{*} = \dim\mathbb{P}\left(V\right) - \dim X -1 $. 
\end{lema}
\begin{proof}
Recordamos que 
\[\dim X = \dim_{\K}\hat{X} - 1.\]
Como $\displaystyle \widehat{X^{*}} = \widehat{\mathbb{P}\left(\hat{X}^{\perp }\right)} = \hat{X}^{\perp } $, tenemos que
\[
\begin{split}
	\dim X^{*} = & \dim_{\K}\left(\hat{X^{*}}\right)-1 = \dim_{\K}\hat{X}^{\perp }-1 = \dim_{\K}V - \dim_{\K}\hat{X}-1\\
	= &  \dim\mathbb{P}\left(V\right)+1-\left(\dim X +1\right)-1 = \dim\mathbb{P}\left(V\right) + \dim X - 1.
\end{split}
\]

\end{proof}
\begin{eg}
Consideremos $\displaystyle \dim\mathbb{P}\left(V\right) = 2 $. Si $\displaystyle P $ es un punto, tenemos que $\displaystyle \dim P^{*} = 2 - 0 - 1 = 1 $, por lo que el dual de un punto en un espacio proyectivo de dimensión dos es una recta. Similarmente, si $\displaystyle X = \mathbb{P}\left(V\right) $, tenemos que $\displaystyle \dim X^{*} = 2 - 2 - 1 = 0 $, por lo que $\displaystyle X^{*} = \emptyset $. 
\end{eg}
\begin{observation}[Principio de dualidad]
Si $\displaystyle \mathcal{E} $ es un enunciado sobre variedades de $\displaystyle \mathbb{P}\left(V\right) $ que se expresa con $\displaystyle \forall $, $\displaystyle \exists $, $\displaystyle \subset  $, $\displaystyle \dim  $, $\displaystyle \cap  $, $\displaystyle + $ y negación, y obtenemos $\displaystyle \mathcal{E}^{*} $, un enunciado dual sustituyendo 
\[\dim = d \leftrightarrow \dim\mathbb{P}\left(V\right)-d-1 .\]
\[\subset \leftrightarrow \supset .\]
\[\cap \leftrightarrow + .\]
Entonces, $\displaystyle \mathcal{E} $ es cierto si y solo si $\displaystyle \mathcal{E}^{*} $ es cierto.
\end{observation}
\begin{eg}
Consideremos el enunciado \\ \\ 
$\displaystyle \mathcal{E} $: 'Todo par de hiperplanos de un espacio proyectivo de dimensión $\displaystyle n $ tiene intersección no vacía'. \\ \\
El enunciado dual sería, \\ \\
$\displaystyle \mathcal{E}^{*} $: 'Todo par de puntos de un espacio proyectivo de dimensión $\displaystyle n $ generan una variedad que está contenida en un hiperplano'.
\end{eg}
\section{Coordenadas y dualidad}
\begin{definition}[Bases duales]
	Dos referencias proyectivas, $\displaystyle \mathcal{R} $ de $\displaystyle \mathbb{P}\left(V\right) $ y $\displaystyle \mathcal{R}^{*} $ de $\displaystyle \mathbb{P}\left(V^{*}\right) $, son \textbf{duales} si admiten bases asociadas $\displaystyle \mathcal{B} $ y $\displaystyle \mathcal{B}^{*} $ duales. Es decir, $\displaystyle \mathcal{B} = \left\{ v_{0}, \ldots, v_{n}\right\}  $ y $\displaystyle \mathcal{B}^{*} = \left\{ \phi_{0}, \ldots, \phi_{n}\right\}  $ con 
	\[\phi_{j}\left(v_{i}\right) = 
	\begin{cases}
	1, \; i = j \\ 
	0, \; i \neq j 
	\end{cases}
	.\]
\end{definition}
\begin{observation}
	Sea $\displaystyle H = \left\{ a_{0}x_{0} + \cdots + a_{n}x_{n} = 0\right\} \subset \mathbb{P}\left(V\right) $ un hiperplano dado en la referencia $\displaystyle \mathcal{R} $, tenemos que 
	\[a_{0}\phi_{0} + \cdots + a_{n}\phi_{n} \in V^{*} .\]
Así, tendremos que 
\[
\begin{split}
	\left(x_{0}, \ldots, x_{n}\right) \in \hat{H} \iff & a_{0}x_{0} + \cdots + a_{n}x_{n} = 0 \\
	\iff & a_{0}\phi_{0}\left(x_{0}, \ldots, x_{n}\right) + \cdots + a_{n}\phi_{n}\left(x_{0}, \ldots, x_{n}\right) = 0 \\
	\iff & \left(a_{0}\phi_{0} + \cdots + a_{n}\phi_{n}\right)\left(x_{0}, \ldots, x_{n}\right) = 0 \\
	\iff & \hat{H}^{\perp } = L\left(a_{0}\phi_{0}+\cdots + a_{n}\phi_{n}\right) .
\end{split}
\]
Así, tenemos que $\displaystyle H^{*} = \mathbb{P}\left(\hat{H}^{\perp }\right) = [a_{0}: \cdots : a_{n}]_{\mathcal{R}^{*}} $. 
\end{observation}
\begin{eg}
En $\displaystyle \mathbb{P}^{2} $ vamos a calcular la intersección de dos rectas sin resolver un sistema. Consideremos 
\[L_{1} = \left\{ x_{0}-3x_{1}+2x_{2} = 0\right\}, \quad L_{2}= \left\{ 5x_{0}-4x_{1}-3x_{2} = 0\right\}  .\]
Tenemos que $\displaystyle L_{1}\cap L_{2} = P\iff L_{1}^{*} + L_{2}^{*} = P^{*} $. Está claro que $\displaystyle L_{1} $ y $\displaystyle L_{2} $ son hiperplanos de $\displaystyle \mathbb{P}^{2} $. Tenemos que 
\[L_{1}^{*}= [1:-3:2], \quad L_{2}^{*} = [5:-4:-3] .\]
Tenemos que $\displaystyle P^{*} $ es la recta que pasa por $\displaystyle L_{1}^{*} $ y $\displaystyle L_{2}^{*} $. Así, 
\[P = \left\{ [x_{0}:x_{1}:x_{2}] \; : \; \begin{vmatrix} x_{0} & 1 & 5 \\ x_{1} & -3 & - 4 \\ x_{2} & 2 & - 3 \end{vmatrix} = 0\right\} = \left\{ 17x_{0}+13x_{1}+11x_{2} = 0\right\}  .\]
Así, nos queda que $\displaystyle P = \left(P^{*}\right)^{*} = [17:13:11] $.
\end{eg}
\begin{observation}
En general, si $\displaystyle \mathcal{R} $ y $\displaystyle \mathcal{R}^{*} $ son referencias duales y 
\[X = 
\begin{cases}
a_{10}x_{0} + \cdots + a_{1n}x_{n} = 0 \\ 
\vdots \\ 
a_{n-d,0}x_{0}+\cdots + a_{n-d,n}x_{n} = 0
\end{cases}
,\]
es una variedad de dimensión $\displaystyle d $ de $\displaystyle \mathbb{P}\left(V\right) $ en la referencia $\displaystyle \mathcal{R} $, tenemos que 
\[\hat{X} = \left\{ \left(x_{0}, \ldots, x_{n}\right)_{\mathcal{B}} \; : \; \begin{pmatrix} a_{10} & \cdots & a_{1n} \\
\vdots & & \vdots \\
a_{n-d,0} & \cdots & a_{n-d, n}\end{pmatrix}\begin{pmatrix} x_{0} \\ \vdots \\ x_{n} \end{pmatrix} = \begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix}\right\}  .\]
Así, tendremos que 
\[\hat{X}^{\perp} = L\left(a_{10}\phi_{0} + \cdots + a_{1n}\phi_{n}, \ldots, a_{n-d,0}\phi_{0}+\cdots + a_{n-d,n}\phi_{n}\right).\]
Por tanto, 
\[X^{*} = \left\{ [x_{0}: \cdots : x_{n}]_{\mathcal{R}^{*}} \; : \; \begin{pmatrix} x_{0} \\ \vdots \\ x_{n} \end{pmatrix} = \begin{pmatrix} a_{10} & \cdots & a_{n-d,0} \\
\vdots & & \vdots \\
a_{1,n} & \cdots & a_{n-d, n}\end{pmatrix}\begin{pmatrix} \lambda_{1} \\ \vdots \\ \lambda_{n-d} \end{pmatrix}, \; \lambda_{1}, \ldots, \lambda_{n-d} \in \K\right\}  .\]
\end{observation}
\begin{eg}[Dual de un cubo]
	Consideremos en $\displaystyle \R^{3} $ el cubo de vértices $\displaystyle \left(\pm1, \pm1, \pm1\right) $. Podemos situar $\displaystyle \R^{3} $ dentro de un espacio proyectivo: $\displaystyle \R^{3} = \mathbb{P}^{3}/ \left\{ x_{0} = 0\right\}  $, es decir, 
	\[ \left(x_{1}, x_{2}, x_{3}\right) \to [1:x_{1}:x_{2}:x_{3}] .\]
	Consideremos la variedad $\displaystyle S = \left\{ x_{3}=1\right\}  $, es decir, la cara superior del cubo. Tenemos que $\displaystyle \overline{S} = \left\{ x_{3} = x_{0}\right\}  $ y
	\[\overline{S}^{*} = [1:0:0:-1] .\]
	Consideremos ahora un vértice del cubo, por ejemplo $\displaystyle P = \left(1,1,1\right) $. Tenemos que $\displaystyle \overline{P} = [1:1:1:1] $ y 
	\[\overline{P} = 
	\begin{cases}
	x_{0} = x_{1} \\
	x_{0} = x_{2} \\ 
	x_{0} = x_{3}
	\end{cases}
	.\]
	Así, tenemos que podemos calcular $\displaystyle \overline{P}^{*} $ de la siguiente forma:
	\[
	\begin{split}
		\overline{P}^{*} = & \mathbb{P}\left(L\left(\left(1,0,0,-1\right), \left(1,-1,0,0\right), \left(1,0,-1,0\right)\right)\right) \\
		= & \left\{ \begin{vmatrix} x_{0} & 1 & 1 & 1 \\ x_{1} & 0 & -1 & 0 \\ x_{2} & 0 & 0 & -1\\ x_{3} & -1 & 0 & 0 \end{vmatrix} = 0\right\}  = \left\{ x_{0}+x_{1}+x_{2}+x_{3}= 0\right\}  .
	\end{split}
	\]
	Consideremos ahora la recta $\displaystyle l = \left\{ x_{3}=1, x_{1}=1\right\}  $. Tenemos que 
	\[\overline{l} = 
	\begin{cases}
	x_{3}= x_{0} \\ 
	x_{1}= x_{0}
	\end{cases}
	.\]
Así, nos queda que su dual será
\[
\begin{split}
	\overline{l}^{*} = & \mathbb{P}\left(L\left(\left(1,0,0,-1\right), \left(1, -1, 0, 0\right)\right)\right) \\
	= & \left\{ [x_{0}:x_{1}:x_{2}:x_{3}] \; : \; \ran\begin{pmatrix} x_{0} & 1 & 1 \\ x_{1} & 0 & - 1 \\ x_{2} & 0 & 0 \\ x_{3} & -1 & 0 \end{pmatrix}=2\right\} = \left\{ x_{2} = 0, \; x_{0}+x_{1}+x_{3}=0\right\} .
\end{split}
\]
Ahora, podemos volver a $\displaystyle \R^{3} $ restringiendo las variedades duales a $\displaystyle \mathbb{P}^{3}/ \left\{ x_{0} = 0\right\}  $. 
\end{eg}
\begin{definition}[Haz de hiperplanos]
Sea $\displaystyle X \subset \mathbb{P}\left(V\right) $ una variedad con $\displaystyle \dim X = \dim\mathbb{P}\left(V\right) -2 $. El conjunto 
\[h\left(X\right)= \left\{ H \; \text{hiperplano} \; : \; X \subset H\right\}  ,\]
es el \textbf{haz de hiperplanos} con base $\displaystyle X $.
\end{definition}
\begin{eg}
En $\displaystyle \mathbb{P}^{2} $ sea $\displaystyle X $ un punto. Tenemos que $\displaystyle h\left(X\right) $ es el conjunto de rectas que pasan por $\displaystyle X $. Análogamente, en $\displaystyle \mathbb{P}^{3} $ si $\displaystyle X $ es una recta, tenemos que $\displaystyle h\left(X\right) $ es el conjunto de los planos que continenen a $\displaystyle X $. 
\end{eg}
\begin{observation}
Sea $\displaystyle X \subset \mathbb{P}\left(V\right) $ con $\displaystyle \dim X = \dim \mathbb{P}\left(V\right)-2 $. Tenemos que 
\[\dim X^{*} = \dim\mathbb{P}\left(V\right)-\dim X - 1 = \dim \mathbb{P}\left(V\right)-\dim\mathbb{P}\left(V\right)+2-1 = 1 .\]
Por tanto, $\displaystyle X^{*} $ es una recta de $\displaystyle \mathbb{P}\left(V^{*}\right) $. Además, tenemos que 
\[ X^{*}= \mathbb{P}\left(\hat{X}^{\perp }\right) = \mathbb{P}\left( \left\{ \omega \in \Hom\left(V, \K\right) \; : \; \omega\left(x\right) = 0, \; \forall x \in \hat{X}\right\} \right) = h\left(X\right).\]
\end{observation}
\section{Aplicaciones duales}
Sea $\displaystyle \mathcal{B} $ una base de $\displaystyle V $ y $\displaystyle \mathcal{B}' $ una base de $\displaystyle V' $. Consideremos $\displaystyle \mathcal{B}^{*} $ y $\displaystyle \mathcal{B}'^{*} $ las bases duales de las anteriores, respectivamente. Dada $\displaystyle f : V \to V' $ lineal, definimos la \textbf{aplicación lineal dual} de la siguiente forma:
\[f^{*} : V'^{*} \to V^{*} : \omega \in \Hom\left(V', \K\right) \to \omega\circ f \in \Hom\left(V, \K\right) .\]
Sean $\displaystyle \mathcal{B} = \left\{ v_{1}, \ldots, v_{n}\right\}  $, $\displaystyle \mathcal{B}' = \left\{ u_{1}, \ldots, u_{m}\right\}  $, $\displaystyle \mathcal{B}^{*} = \left\{ \phi_{1}, \ldots, \phi_{n}\right\}  $ y $\displaystyle \mathcal{B}'^{*} = \left\{ \psi_{1}, \ldots, \psi_{m}\right\}  $. Tenemos que 
\[f\left(v_{i}\right)=\sum^{m}_{k=1}a_{ki}u_{k}, \quad f^{*}\left(\psi{i}\right) = \sum^{n}_{k = 1}b_{ki}\phi_{k} .\]
Ahora, tenemos que 
\[a_{ij} = \psi_{i}\left(f\left(v_{j}\right)\right) = \psi_{i}\left(\sum^{m}_{k = 1}a_{kj}u_{k}\right) = f^{*}\left(\psi_{i}\right)\left(v_{j}\right) = \left(\sum^{n}_{k = 1}b_{ki}\phi_{k}\right)\left(v_{j}\right) = b_{ji} .\]
Por tanto, tenemos que  
\[\boxed{ \mathcal{M}_{\mathcal{B}^{*}\mathcal{B}'^{*}}\left(f^{*}\right) = \left(\mathcal{M}_{\mathcal{B}\mathcal{B}'}\left(f\right)\right)^{T}.} \]

\begin{lema}
Sean $\displaystyle f : V \to V' $ y $\displaystyle g : V' \to V'' $ duales. Entonces
\[\left(g\circ f\right)^{*} = f^{*}\circ g^{*} .\]
\end{lema}
\begin{proof}
Sea $\displaystyle \omega \in \Hom\left(V'', \K\right) $, entonces
\[\left(g\circ f\right)^{*}\left(\omega \right) = \omega \circ \left(g \circ f\right) = f^{*} \left(\omega \circ g\right) = f^{*} \circ g^{*} \left(\omega \right) .\]
\end{proof}
Dada una aplicación proyectiva $\displaystyle f : \mathbb{P}\left(V\right) \to \mathbb{P}\left(V'\right) $, con aplicación lineal asociada $\displaystyle \hat{f} : V \to V' $, definimos 
\[ f^{*} : \mathbb{P}\left(V^{*}\right) \to \mathbb{P}\left(V'^{*}\right) : [\omega] \to [\hat{f}^{*}\left(\omega\right)] = [\omega\circ \hat{f}].\]
Como $\displaystyle \left(\lambda \hat{f}\right)^{*} = \lambda \hat{f}^{*} $, $\displaystyle \forall \lambda \in \K $, tenemos que $\displaystyle f^{*} $ está bien definido. Además, $\displaystyle Z\left(f^{*}\right) = \left(\Imagen\left(f\right)\right)^{*} $. En efecto, tenemos que 
\[
\begin{split}
	Z\left(f^{*}\right) = & \mathbb{P}\left(\Ker\left(\hat{f}^{*}\right)\right) = \mathbb{P}\left( \left\{ \omega \in \Hom\left(V', \K\right) \; : \; \omega \circ \hat{f} = 0\right\} \right) \\
	= & \mathbb{P}\left( \left\{ \omega \in \Hom\left(V', \K\right) \; : \; \omega\left(x\right) = 0, \; \forall x \in \Imagen\left(\hat{f}\right)\right\} \right) = \mathbb{P}\left(\Imagen\left(\hat{f}\right)^{\perp }\right) = \Imagen\left(f\right)^{*}.
\end{split}
\]
\begin{lema}
Consideremos $\displaystyle f : \mathbb{P}\left(V\right) \to \mathbb{P}\left(V'\right) $ y $\displaystyle g : \mathbb{P}\left(V'\right)\to \mathbb{P}\left(V''\right) $. Entonces, 
\begin{enumerate}
\item $\displaystyle \left(g\circ f\right)^{*} = f^{*} \circ g^{*} $.
\item $\displaystyle f^{*} $ es inyectiva $\displaystyle \iff  $ $\displaystyle f $ es sobreyectiva. 
\item $\displaystyle f^{*} $ es sobreyectiva $\displaystyle \iff  $ $\displaystyle f $ es inyectiva. 
\item $\displaystyle f^{*} $ es biyectiva $\displaystyle \iff  $ $\displaystyle f $ es biyectiva. Además, $\displaystyle \left(f^{-1}\right)^{*} = \left(f^{*}\right)^{-1} $. 
\end{enumerate}
\end{lema}
\begin{proof}
\begin{enumerate}
\item Es consecuencia de que $\displaystyle \left(g\circ f\right)^{*} = f^{*}\circ g^{*} $.
\item Es consecuencia de que $\displaystyle f^{*} $ es inyectiva si y solo si $\displaystyle \hat{f}^{*} $ también lo es, y de que $\displaystyle Z\left(f^{*}\right) = \emptyset $ si y solo si $\displaystyle f $ es suprayectiva. 
\item Con Ancochea fue demostrado para espacios vectoriales, de ahí es fácil extenderlo al espacio proyectivo. 
\item La primera parte es consecuencia de los dos apartados anteriores. Por otro lado
	\[\left(\widehat{f^{-1}}\right)^{*} = \left(\hat{f}^{-1}\right)^{*} = \left(\hat{f}^{*}\right)^{-1} .\]	
La segunda igualdad ha sido demostrada por Ancochea el año pasado.
\end{enumerate}
\end{proof}
\subsection{Subvariedades invariantes por homografías}
\begin{definition}[Variedad invariante]
Sea $\displaystyle f : \mathbb{P}\left(V\right) \to \mathbb{P}\left(V\right) $ una homografía. Se dice que $\displaystyle X \subset \mathbb{P}\left(V\right) $ es una \textbf{variedad invariante por} $\displaystyle f $ si $\displaystyle f\left(X\right) \subset X $ \footnote{Esto es equivalente a que $\displaystyle f\left(X\right) = X $ puesto que $\displaystyle f $ es una homografía. En efecto, si $\displaystyle f\left(X\right)\subset X $ y $\displaystyle \dim X = \dim f\left(X\right) $ está claro que $\displaystyle X = f\left(X\right) $.}.
\end{definition} 
\subsection*{Puntos fijos}
Un punto $\displaystyle P \in \mathbb{P}\left(V\right) $ es fijo si $\displaystyle f\left(P\right) = P $, que es cierto si y solo si 
\[P = [x_{0}:\cdots:x_{n}], \; \exists \lambda \in \K^{*}, \lambda \begin{pmatrix} x_{0} \\ \vdots \\ x_{n} \end{pmatrix} = M\left(f\right) \begin{pmatrix} x_{0} \\ \vdots \\ x_{n} \end{pmatrix} .\]
Esto es cierto si y solo si $\displaystyle P = [v] $ es un autovector para $\displaystyle \lambda \neq 0 $. Así, tendremos que $\displaystyle \lambda  $ es raíz del polinomio
\[p\left(t\right) = \det\left(M_{\mathcal{B}}\left(\hat{f}\right)-t I\right) .\]
Dependiendo de $\displaystyle \K $ puede haber puntos fijos o no. Por ejemplo, si $\displaystyle \K = \C $, el polinomio característico de $\displaystyle \hat{f} $ siempre tiene raíces, pero si $\displaystyle \K = \Q $ o $\displaystyle \K = \R $ no siempre tiene raíces. Fijado $\displaystyle \lambda  $ raíz de $\displaystyle p\left(t\right) $, tomamos
\[\hat{X}_{\lambda} = \Ker\left(\hat{f}-\lambda id\right), \; X_{\lambda }= \mathbb{P}\left(\hat{X}_{\lambda }\right) .\]
Así, tenemos que $\displaystyle X_{\lambda } $ es una variedad de puntos fijos de $\displaystyle f $. 
\subsection*{Hiperplanos invariantes}
Un hiperplano $\displaystyle H = \left\{ b_{0}x_{0}+\cdots + b_{n}x_{n} = 0\right\}  $ es invariante para $\displaystyle f $ si y solo si 
\[f\left(H\right) \subset H \iff f^{*}\left(H\right) \supset H^{*} \iff f^{*}\left([b_{0}: \cdots : b_{n}]\right) = [b_{0}: \cdots : b_{n}].\]
Esto es cierto si y solo si existe $\displaystyle \lambda \in \K^{*} $ tal que 
\[\lambda \begin{pmatrix} b_{0} \\ \vdots \\ b_{n} \end{pmatrix} = M_{\mathcal{B}^{*}}\left(\hat{f}^{*}\right)\begin{pmatrix} b_{0} \\ \vdots \\ b_{n} \end{pmatrix} \iff \lambda \begin{pmatrix} b_{0} \\ \vdots \\ b_{n} \end{pmatrix} = M_{\mathcal{B}}\left(\hat{f}\right)^{T}\begin{pmatrix} b_{0} \\ \vdots \\ b_{n} \end{pmatrix} .\]
Esto es cierto si y solo si 
\[\begin{pmatrix} b_{0} \\ \vdots \\ b_{n} \end{pmatrix} \in \Ker\left(M_{\mathcal{B}}\left(\hat{f}\right)^{T} - \lambda id \right) .\]
Esto es cierto si y solo si $\displaystyle \lambda  $ es raíz del polinomio característico de $\displaystyle M_{\mathcal{B}}\left(\hat{f}\right)^{T} $, que coincide con el polinomio característico de $\displaystyle \hat{f} $. Si tomamos 
\[\hat{Y}_{\lambda } = \Ker\left(M_{\mathcal{B}}\left(\hat{f}\right)^{T}-\lambda id\right) , \]
tenemos que 
\[\mathbb{P}\left(\hat{Y}_{\lambda }\right)^{*} = \left\{ b_{0}x_{0} + \cdots + b_{n}x_{n} = 0 \; : \; \left(b_{0}, \ldots, b_{n}\right) \in \hat{Y}_{\lambda}- \left\{ 0\right\} \right\}  ,\]
que es una familia de hiperplanos invariantes para $\displaystyle f $. 
\begin{lema}
Sean $\displaystyle X_{1}, X_{2} $ variedades invariantes para una homografía $\displaystyle f : \mathbb{P}\left(V\right)\to \mathbb{P}\left(V\right) $ y $\displaystyle \dim\mathbb{P}\left(V\right) < \infty $. Entonces, $\displaystyle X_{1} \cap X_{2} $ y $\displaystyle X_{1} + X_{2} $ son invariantes para $\displaystyle f $.
\end{lema}
\begin{proof}
Tenemos que $\displaystyle f\left(X_{1}\right) \subset X_{1} $ y $\displaystyle f\left(X_{2}\right) \subset X_{2} $. Así, tenemos que 
\[f\left(X_{1} \cap X_{2}\right) \subset f\left(X_{1}\right) \cap f\left(X_{2}\right) \subset X_{1} \cap X_{2} .\]
Por tanto, $\displaystyle X_{1} \cap X_{2} $ es invariante. Ahora, tenemos que $\displaystyle X_{1} + X_{2} = V\left(X_{1} \cup X_{2}\right) $. Así, tenemos que 
\[f\left(X_{1}\right)\cup f\left(X_{2}\right) \subset f\left(X_{1}\right) + f\left(X_{2}\right), \quad f\left(X_{1}\right)\cup f\left(X_{2}\right) \subset f\left(X_{1}+X_{2}\right) .\]
Así, tenemos que $\displaystyle f\left(X_{1}\right)+f\left(X_{2}\right) \subset f\left(X_{1} + X_{2}\right) $. Por ser homografía, tenemos que $\displaystyle f\left(X_{1}\right) = X_{1} $ y $\displaystyle f\left(X_{2}\right) = X_{2} $. Así, tenemos que 
\[X_{1} + X_{2} \subset f\left(X_{1} + X_{2}\right) .\]
Por ser $\displaystyle f $ homografía tenemos que $\displaystyle \dim\left(X_{1} + X_{2}\right)= \dim f\left(X_{1} + X_{2}\right) $, por lo que $\displaystyle X_{1} + X_{2} = f\left(X_{1} + X_{2}\right) $. 
\end{proof}
\begin{eg}
Consideremos  
\[  f : \mathbb{P}^{3} \to \mathbb{P}^{3} : [x_{0}:x_{1}:x_{2}:x_{3}] \to [x_{0}+x_{1}:x_{1}+x_{2}:x_{2}+x_{3}:2x_{3}].\]
Tenemos que
\[M\left(f\right) = \begin{pmatrix} 1 & 1 & & \\ & 1 & 1 & \\ & & 1 & 1 \\ & & & 2 \end{pmatrix} .\]
Tenemos que el polinomio característico será $\displaystyle P_{M}\left(t\right) = \det\left(M - t id\right)=\left(1-t\right)^{3}\left(2-t\right) $, por lo que los autovalores son $\displaystyle \lambda \in \left\{ 1,2\right\}  $. 
\begin{itemize}
\item Los puntos fijos para $\displaystyle \lambda = 1 $ son:
	\[\left(M - \lambda I\right)\begin{pmatrix} x_{0} \\ \vdots \\ x_{3} \end{pmatrix}=\begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix} \Rightarrow 
	\begin{cases}
	x_{0} = 0 \\ 
	x_{1} = 0 \\
	x_{2} = 0 \\
	x_{3} = 0
	\end{cases}
.\]
Así, tenemos que la variedad de los puntos fijos para $\displaystyle \lambda = 1 $ es $\displaystyle X_{1} = [1:0:0:0] $. 
\item Los puntos fijos para $\displaystyle \lambda = 2 $ serán 
	\[\left(M - 2 I\right) \begin{pmatrix} x_{0} \\ \vdots \\ x_{3} \end{pmatrix}= \begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix} \Rightarrow 
\begin{cases}
-x_{0}+x_{1} = 0 \\
-x_{1} + x_{2} = 0 \\
-x_{2}+x_{3} = 0
\end{cases}
.\]
Así, la variedad de puntos fijos para $\displaystyle \lambda = 2 $ será $\displaystyle X_{2} = [1:1:1:1] $. 
\item Los hiperplanos invariantes para $\displaystyle \lambda = 1 $ será:
	\[ \left(M^{t}-I\right)\begin{pmatrix} b_{0} \\ \vdots \\ b_{3} \end{pmatrix}=\begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix} \Rightarrow 
\begin{cases}
b_{0} = 0 \\
b_{1} = 0 \\
b_{2}+b_{3}=0
\end{cases}
.\]
Así, nuestra familia de hiperplanos invariantes para $\displaystyle \lambda = 1 $ son $\displaystyle H = \left\{ x_{2}-x_{3} = 0\right\} = [0 : 0 : 1 : - 1]^{*} $. 
\item Los hiperplanos invariantes para $\displaystyle \lambda = 2 $ serán:
	\[\left(M^{t}-2I\right)\begin{pmatrix} b_{0} \\ \vdots \\ b_{3} \end{pmatrix}=\begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix} \Rightarrow
\begin{cases}
-b_{0} = 0 \\
b_{0}-b_{1} = 0 \\
b_{1}-b_{2} = 0 \\
b_{2}=0
\end{cases}
.\]
Así, $\displaystyle H = \left\{ x_{3}=0\right\} = [0:0:0:1] ^{*}$ es nuestra familia de hiperplanos invariantes para $\displaystyle \lambda = 2 $. 
\item Calculamos las rectas invariantes. Sabemos que las rectas que pasan por los dos puntos fijos es una recta invariante. Análogamente la recta que resulta de la intersección de los dos hiperplanos es otra recta invariante. La pregunta es, hay más rectas invariantes?
\end{itemize}

\end{eg}


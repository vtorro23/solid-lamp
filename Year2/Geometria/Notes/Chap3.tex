\chapter{Dualidad}
\section{Repaso del espacio dual}
Sea $\displaystyle V $ un $\displaystyle \K  $-espacio vectorial. Decíamos que $\displaystyle V^{*}=\Hom\left(V, \K\right) $ es el \textbf{espacio dual}, donde $\displaystyle V^{*} $ también es un $\displaystyle \K $-espacio vectorial. En efecto, si $\displaystyle \phi, \psi \in \Hom\left(V, \K\right) $, tenemos que 
\[\left(\phi + \psi\right)\left(v\right) : = \phi\left(v\right) + \psi\left(v\right), \; \forall v \in V .\]
Análogamente, si $\displaystyle \lambda \in \K $ y $\displaystyle \phi \in \Hom\left(V, \K\right) $ tenemos que 
\[\left(\lambda \phi\right)\left(v\right) : = \lambda\left(\phi\left(v\right)\right), \; \forall v \in V .\]
Sea $\displaystyle \mathcal{B} = \left\{ v_{1}, \ldots, v_{n}\right\}  $ una base de $\displaystyle V $. Definimos $\displaystyle \phi_{i} : V \to \K $ de forma que 
\[\phi_{i}\left(v_{j}\right) = 
\begin{cases}
1, \; i= j \\ 
0, \; i \neq j
\end{cases}
, \; \forall j = 1, \ldots, n.\]
Veamos que $\displaystyle \mathcal{B}^{*} = \left\{ \phi_{1}, \ldots, \phi_{n}\right\}  $ es una base de $\displaystyle V^{*} $. Sea $\displaystyle \phi \in V^{*} $ y sea $\displaystyle u = \left(x_{1}, \ldots, x_{n}\right)_{\mathcal{B}} \in V $. Tenemos que 
\[\phi\left(u\right) = \phi\left(x_{1}v_{1} + \cdots + x_{n}v_{n}\right) = x_{1}\phi\left(v_{1}\right) + \cdots + x_{n}\phi\left(v_{n}\right) .\]
Por otro lado, tenemos que 
\[
\begin{split}
	\left(\phi\left(v_{1}\right)\phi_{1} + \cdots + \phi\left(v_{n}\right)\phi_{n}\right)\left(u\right) = & \phi\left(v_{1}\right)\phi_{1}\left(u\right) + \cdots + \phi\left(v_{n}\right)\phi_{n}\left(u\right) \\
	= & \phi\left(v_{1}\right)\phi_{1}\left(x_{1}v_{1} + \cdots + x_{n}v_{n}\right) + \cdots + \phi\left(v_{n}\right)\phi_{n}\left(x_{1}v_{1} + \cdots + x_{n}v_{n}\right) \\
	= & \phi\left(v_{1}\right)\sum^{n}_{i = 1}x_{i}\phi_{1}\left(v_{i}\right) + \cdots + \phi\left(v_{n}\right)\sum^{n}_{i = 1}x_{i}\phi_{n}\left(v_{i}\right) \\
	= & x_{1}\phi\left(v_{1}\right) + \cdots + x_{n}\phi\left(v_{n}\right) .
\end{split}
\]
Veamos que $\displaystyle \mathcal{B}^{*} $ son linealmente independientes. Supongamos que 
\[0 = \lambda_{1}\phi_{1} + \cdots + \lambda_{n}\phi_{n} .\]
Tenemos entonces que 
\[0 = \lambda_{1}\phi_{1}\left(v_{i}\right) + \cdots + \lambda_{n}\phi_{n}\left(v_{i}\right) = \lambda_{i} .\]
Por tanto, tenemos que $\displaystyle \lambda_{i} = 0 $, $\displaystyle \forall i = 1, \ldots, n $ y en consecuencia son linealmente independientes. 
\begin{colorary}
Si $\displaystyle \dim_{\K}V < \infty $, entonces $\displaystyle \dim_{\K}V = \dim_{\K}V^{*} $ \footnote{Si la dimensión es infinita también es cierto pero no nos vale la demostración anterior.}. 
\end{colorary}
Supongamos que $\displaystyle \dim_{\K}V < \infty $ y veamos que hay un isomorfismo canónico entre $\displaystyle V $ y $\displaystyle V^{**} = \left(V^{*}\right)^{*} = \Hom\left(V^{*}, \K\right) $. Este viene dado por la función 
\[\ev : V \to V^{**} : u \to \ev_{u} ,\quad \ev_{u} : V^{*} \to \K : \phi \to \ev_{u}\left(\phi\right) = \phi\left(u\right).\]
Veamos que es un isomorfismo:
\[\ev_{u_{1}+u_{2}}\left(\phi\right) = \phi\left(u_{1} + u_{2}\right) = \phi\left(u_{1}\right) + \phi\left(u_{2}\right) = \ev_{u_{1}}\left(\phi\right) + \ev_{u_{2}}\left(\phi\right), \; \forall \phi \in V^{*} .\]
\[ev_{\lambda u}\left(\phi\right) = \phi\left(\lambda\right) = \lambda \phi\left(u\right) = \lambda \ev_{u}\left(\phi\right), \; \forall \phi \in V^{*} .\]
Así, hemos visto que $\displaystyle \ev $ es lineal. Veamos ahora que $\displaystyle \ev $ es inyectiva. 
\[
\begin{split}
	\ev_{u} = 0 \iff & \ev_{u}\left(\phi\right) = 0, \; \forall \phi \in V^{*} \iff \phi\left(u\right) = 0, \; \forall \phi \in V^{*} \iff \phi_{i}\left(u\right) = 0, \; \forall \phi_{i}\in \mathcal{B}^{*} \\
	\iff & u = 0 \iff  \Ker\left(\ev\right) = \left\{ 0\right\}   .
\end{split}
\]
Como $\displaystyle \dim_{\K}V = \dim_{\K}V^{*} = \dim_{\K}\left(V^{**}\right) < \infty $, con ver que es inyectiva hemos visto que es biyectiva y por tanto es un isomorfismo. Abusando de la notación, identificamos $\displaystyle V $ con $\displaystyle V^{**} $ mediante $\displaystyle u = \ev_{u} $. \\ \\ 
Dado $\displaystyle U \in \mathcal{L}\left(V\right) $, podemos definir el \textbf{ortogonal} de $\displaystyle U $ de la forma
\[U^{\perp } = \left\{ \phi \in V^{*} \; : \; \phi\left(u\right) = 0, \; \forall u \in U\right\}  .\]
\begin{prop}
Se cumple, 
\begin{enumerate}
\item $\displaystyle U^{\perp } $ es un $\displaystyle \K $-subespacio vectorial de $\displaystyle V^{*} $. 
\item Si $\displaystyle U \subset W $, entonces $\displaystyle W^{\perp } \subset U^{\perp } $. 
\item $\displaystyle \dim_{\K}U^{\perp } = \dim_{\K}V - \dim_{\K}U $. 
\item $\displaystyle V^{\perp } = \left\{ 0\right\}  $ y $\displaystyle \left\{ 0\right\} ^{\perp } = V^{*} $.
\end{enumerate}
\end{prop}
\begin{proof}
\begin{enumerate}
\item Claramente $\displaystyle U^{\perp } \neq \emptyset $ puesto que $\displaystyle 0 \in U^{\perp } $. Ahora, sean $\displaystyle \phi_{1}, \phi_{2} \in U^{\perp } $ y $\displaystyle u \in U $, 
	\[\left(\phi_{1} + \phi_{2}\right)\left(u\right) =\phi_{1}\left(u\right) + \phi_{2}\left(u\right) = 0 \Rightarrow \phi_{1} + \phi_{2} \in U^{\perp } .\]
	Además, sea $\displaystyle \phi \in U^{\perp } $, $\displaystyle \lambda \in \K $ y $\displaystyle u \in U $,
	\[\left(\lambda\phi\right)\left(u\right) = \lambda\left(\phi\left(u\right)\right) = \lambda \cdot 0 = 0 \Rightarrow \lambda \phi \in U^{\perp } .\]
\item Sea $\displaystyle u \in U \subset W $. Si $\displaystyle \phi \in W^{\perp } $ tenemos que $\displaystyle \phi\left(u\right) = 0 $, $\displaystyle \forall u \in U \subset W $, por lo que $\displaystyle \phi \in U^{\perp } $ y en consecuencia $\displaystyle W^{\perp }\subset U^{\perp } $. 
\item Sea $\displaystyle \dim_{\K}U = k $ y $\displaystyle \dim_{\K}V = n $. Sea $\displaystyle \left\{ u_{1}, \ldots, u_{k}\right\}  $ una base de $\displaystyle U $ y la ampliamos a $\displaystyle \left\{ u_{1}, \ldots, u_{n}\right\}  $ base de $\displaystyle V $. Sea $\displaystyle \mathcal{B}^{*} = \left\{ \phi_{1}, \ldots, \phi_{n}\right\}  $ la base dual de la anterior. Tenemos que $\displaystyle \phi_{k+1}, \ldots, \phi_{n} \in U^{\perp } $, puesto que $\displaystyle \forall u = \lambda_{1}u_{1} + \cdots + \lambda_{k}u_{k} \in U $ tenemos que
	\[\forall j > k, \; \phi_{j}\left(u\right) = \lambda_{1}\phi_{j}\left(u_{1}\right) + \cdots + \lambda_{k}\phi_{j}\left(u_{k}\right) = 0 .\]
	Tenemos que $\displaystyle \phi_{k+1}, \ldots, \phi_{n} $ son linealmente independientes por ser parte de una base. Veamos que generan $\displaystyle U^{\perp } $. Sea $\displaystyle \phi \in U^{\perp } $. Como $\displaystyle \mathcal{B}^{*} $ es base de $\displaystyle V^{*} $, tenemos que 
	\[\phi = a_{1}\phi_{1} + \cdots + a_{n}\phi_{n} .\]
	Además, tenemos que
	\[
	\begin{cases}
	\phi\left(u_{i}\right) = a_{1}\phi_{1}\left(u_{i}\right) + \cdots + a_{n}\phi_{n}\left(u_{i}\right) = a_{i} \\ 
	\phi\left(u_{i}\right) = 0
	\end{cases}
	, \; \forall i= 1, \ldots, k.\]
Por tanto, tenemos que $\displaystyle a_{i} = 0 $, $\displaystyle \forall i = 1, \ldots, k $, por lo que $\displaystyle \phi = a_{k+1}\phi_{k+1} + \cdots + a_{n}\phi_{n} $. 
\item Es fácil ver que $\displaystyle \dim_{\K}V^{*} = 0 $, por lo que $\displaystyle V^{*} = \left\{ 0\right\}  $. Análogamente tenemos que $\displaystyle \dim \left\{ 0\right\} ^{\perp} = \dim_{\K}V  $, así tenemos que $\displaystyle \left\{ 0\right\} ^{\perp} = V^{*} $.
\end{enumerate}
\end{proof}
\begin{prop}
Sea $\displaystyle V $ un $\displaystyle \K $-espacio vectorial con $\displaystyle \dim_{\K}V < \infty $ y $\displaystyle U, W \in \mathcal{L}\left(V\right) $. 
\begin{enumerate}
\item $\displaystyle \left(U^{\perp }\right)^{\perp } = U $ \footnote{Este igual no es estricto puesto que $\displaystyle \left(U^{\perp }\right)^{\perp } \subset V^{**} $, realmente estamos diciendo que $\displaystyle \left(U^{\perp }\right)^{\perp } = \ev\left(U\right) $.}.
\item $\displaystyle \left(U \cap W\right)^{\perp } = U^{\perp } + W^{\perp } $. 
\item $\displaystyle \left(U + W\right)^{\perp } = U^{\perp } \cap W^{\perp } $. 
\item Si $\displaystyle V = U \oplus W $, entonces $\displaystyle V^{*} = U^{\perp }\oplus W^{\perp } $.
\end{enumerate}
\end{prop}
\begin{proof}
\begin{enumerate}
	\item Recordamos que $\displaystyle U^{\perp } = \left\{ \phi \in V^{*} \; : \; \phi\left(u\right) = 0, \; \forall u \in U\right\}  $. Así, tenemos que 
		\[\left(U^{\perp }\right)^{\perp } = \left\{ \ev_{v} \in V^{**} \; : \; \ev_{v}\left(\phi\right) = 0, \; \forall \phi \in U^{\perp }\right\} = \left\{ v \; : \; \phi\left(v\right) = 0, \; \forall \phi \in U^{\perp }\right\} = \ev\left(U\right)  .\]
	\item Tenemos que $\displaystyle U \cap W \subset U, W$, por lo que $\displaystyle U^{\perp } \subset \left(U \cap W \right)^{\perp } $ y $\displaystyle W^{\perp } \subset \left(U \cap W\right)^{\perp } $. Por tanto, tenemos que $\displaystyle U^{\perp } + W^{\perp } \subset \left(U \cap W\right)^{\perp } $. Por otro lado, tenemos que 
		\[U \cap W = \left(\left(U \cap W\right)^{\perp }\right)^{\perp } \subset \left(U^{\perp } + W^{\perp }\right)^{\perp } \subset \left(U^{\perp }\right)^{\perp } \cap \left(W^{\perp }\right)^{\perp } = U \cap W .\]
		Por tanto, debe ser que todos los contenidos son igualdades, en particular, $\displaystyle U \cap W = \left(U^{\perp } + W^{\perp }\right)^{\perp } $. Así, obtenemos que $\displaystyle \left(U \cap W\right)^{\perp } = \left(\left(U^{\perp } + W^{\perp }\right)^{\perp }\right)^{\perp } = U^{\perp } + W^{\perp } $.	
	\item Como $\displaystyle U \subset U + W $ y $\displaystyle W \subset U + W $, tenemos que $\displaystyle \left(U + W\right)^{\perp } \subset U^{\perp }, W^{\perp } $, por lo que $\displaystyle \left(U+W\right)^{\perp } \subset U^{\perp }\cap W^{\perp } $. Tenemos que 
		\[U + W = \left(\left(U + W\right)^{\perp }\right)^{\perp } \supset \left(U^{\perp } \cap W^{\perp }\right)^{\perp }\supset \left(U^{\perp }\right)^{\perp } + \left(W^{\perp }\right)^{\perp } = U + W .\]
	Al igual que en \textbf{(2)}, tenemos que $\displaystyle U + W = \left(U^{\perp }\cap W^{\perp }\right)^{\perp } $, por lo que $\displaystyle \left(U + W\right)^{\perp } = U^{\perp }\cap W^{\perp } $.
\item Consideremos $\displaystyle V = U \oplus W $, es decir, $\displaystyle V = U + W $ y $\displaystyle U \cap W = \left\{ 0\right\}  $. Así, tenemos que $\displaystyle V^{\perp } = U^{\perp }\cap W^{\perp } = \left\{ 0\right\}  $ y $\displaystyle \left\{ 0\right\} ^{\perp } = U^{\perp } + W^{\perp } = V^{*} $. 
\end{enumerate}
\end{proof}
\begin{colorary}
La aplicación 
\[\perp : \mathcal{L}\left(V\right) \to \mathcal{L}\left(V^{*}\right) : U \to U^{\perp } ,\]
es una biyección con sí misma como inversa. Además, cambia $\displaystyle \subset  $ por $\displaystyle \supset  $, y $\displaystyle +  $ por $\displaystyle \cap  $ y viceversa.
\end{colorary}
\section{Dualidad en espacios proyectivos}
Dado un $\displaystyle \K $-espacio vectorial $\displaystyle V $, tenemos que hay una biyección entre las variedades de $\displaystyle \mathbb{P}\left(V\right) $ y los subespacios de $\displaystyle V $. También tenemos una biyección entre los subespacios de $\displaystyle V $ y subespacios de $\displaystyle V^{*} $. En particular
\[ \left\{ X \subset \mathbb{P}\left(V\right) \; : \; X \; \text{variedad}\right\} \leftrightarrow \left\{ X \subset \mathbb{P}\left(V^{*}\right) \; : \; X \; \text{variedad}\right\}  .\]
En efecto, podemos considerar la aplicación $\displaystyle X \to \mathbb{P}\left(\left(\hat{X}\right)^{\perp }\right) $. 
\begin{notation}
Denotamos $\displaystyle X^{*} := \mathbb{P}\left(\left(\hat{X}\right)^{\perp }\right) $. 
\end{notation}
Tenemos que se cumplen las mismas propiedades que hemos demostrado anteriormente para subespacios vectoriales. 
\begin{lema}
Si $\displaystyle \dim\mathbb{P}\left(V\right) = n < \infty $, entonces $\displaystyle \dim X^{*} = \dim\mathbb{P}\left(V\right) - \dim X -1 $. 
\end{lema}
\begin{proof}
Recordamos que 
\[\dim X = \dim_{\K}\hat{X} - 1.\]
Como $\displaystyle \widehat{X^{*}} = \widehat{\mathbb{P}\left(\hat{X}^{\perp }\right)} = \hat{X}^{\perp } $, tenemos que
\[
\begin{split}
	\dim X^{*} = & \dim_{\K}\left(\hat{X^{*}}\right)-1 = \dim_{\K}\hat{X}^{\perp }-1 = \dim_{\K}V - \dim_{\K}\hat{X}-1\\
	= &  \dim\mathbb{P}\left(V\right)+1-\left(\dim X +1\right)-1 = \dim\mathbb{P}\left(V\right) + \dim X - 1.
\end{split}
\]

\end{proof}
\begin{eg}
Consideremos $\displaystyle \dim\mathbb{P}\left(V\right) = 2 $. Si $\displaystyle P $ es un punto, tenemos que $\displaystyle \dim P^{*} = 2 - 0 - 1 = 1 $, por lo que el dual de un punto en un espacio proyectivo de dimensión dos es una recta. Similarmente, si $\displaystyle X = \mathbb{P}\left(V\right) $, tenemos que $\displaystyle \dim X^{*} = 2 - 2 - 1 = 0 $, por lo que $\displaystyle X^{*} = \emptyset $. 
\end{eg}
\begin{observation}[Principio de dualidad]
Si $\displaystyle \mathcal{E} $ es un enunciado sobre variedades de $\displaystyle \mathbb{P}\left(V\right) $ que se expresa con $\displaystyle \forall $, $\displaystyle \exists $, $\displaystyle \subset  $, $\displaystyle \dim  $, $\displaystyle \cap  $, $\displaystyle + $ y negación, y obtenemos $\displaystyle \mathcal{E}^{*} $, un enunciado dual sustituyendo 
\[\dim = d \leftrightarrow \dim\mathbb{P}\left(V\right)-d-1 .\]
\[\subset \leftrightarrow \supset .\]
\[\cap \leftrightarrow + .\]
Entonces, $\displaystyle \mathcal{E} $ es cierto si y solo si $\displaystyle \mathcal{E}^{*} $ es cierto.
\end{observation}
\begin{eg}
Consideremos el enunciado \\ \\ 
$\displaystyle \mathcal{E} $: 'Todo par de hiperplanos de un espacio proyectivo de dimensión $\displaystyle n $ tiene intersección no vacía'. \\ \\
El enunciado dual sería, \\ \\
$\displaystyle \mathcal{E}^{*} $: 'Todo par de puntos de un espacio proyectivo de dimensión $\displaystyle n $ generan una variedad que está contenida en un hiperplano'.
\end{eg}
\section{Coordenadas y dualidad}
\begin{definition}[Bases duales]
	Dos referencias proyectivas, $\displaystyle \mathcal{R} $ de $\displaystyle \mathbb{P}\left(V\right) $ y $\displaystyle \mathcal{R}^{*} $ de $\displaystyle \mathbb{P}\left(V^{*}\right) $, son \textbf{duales} si admiten bases asociadas $\displaystyle \mathcal{B} $ y $\displaystyle \mathcal{B}^{*} $ duales. Es decir, $\displaystyle \mathcal{B} = \left\{ v_{0}, \ldots, v_{n}\right\}  $ y $\displaystyle \mathcal{B}^{*} = \left\{ \phi_{0}, \ldots, \phi_{n}\right\}  $ con 
	\[\phi_{j}\left(v_{i}\right) = 
	\begin{cases}
	1, \; i = j \\ 
	0, \; i \neq j 
	\end{cases}
	.\]
\end{definition}
\begin{observation}
	Sea $\displaystyle H = \left\{ a_{0}x_{0} + \cdots + a_{n}x_{n} = 0\right\} \subset \mathbb{P}\left(V\right) $ un hiperplano dado en la referencia $\displaystyle \mathcal{R} $, tenemos que 
	\[a_{0}\phi_{0} + \cdots + a_{n}\phi_{n} \in V^{*} .\]
Así, tendremos que 
\[
\begin{split}
	\left(x_{0}, \ldots, x_{n}\right) \in \hat{H} \iff & a_{0}x_{0} + \cdots + a_{n}x_{n} = 0 \\
	\iff & a_{0}\phi_{0}\left(x_{0}, \ldots, x_{n}\right) + \cdots + a_{n}\phi_{n}\left(x_{0}, \ldots, x_{n}\right) = 0 \\
	\iff & \left(a_{0}\phi_{0} + \cdots + a_{n}\phi_{n}\right)\left(x_{0}, \ldots, x_{n}\right) = 0 \\
	\iff & \hat{H}^{\perp } = L\left(a_{0}\phi_{0}+\cdots + a_{n}\phi_{n}\right) .
\end{split}
\]
Así, tenemos que $\displaystyle H^{*} = \mathbb{P}\left(\hat{H}^{\perp }\right) = [a_{0}: \cdots : a_{n}]_{\mathcal{R}^{*}} $. 
\end{observation}
\begin{eg}
En $\displaystyle \mathbb{P}^{2} $ vamos a calcular la intersección de dos rectas sin resolver un sistema. Consideremos 
\[L_{1} = \left\{ x_{0}-3x_{1}+2x_{2} = 0\right\}, \quad L_{2}= \left\{ 5x_{0}-4x_{1}-3x_{2} = 0\right\}  .\]
Tenemos que $\displaystyle L_{1}\cap L_{2} = P\iff L_{1}^{*} + L_{2}^{*} = P^{*} $. Está claro que $\displaystyle L_{1} $ y $\displaystyle L_{2} $ son hiperplanos de $\displaystyle \mathbb{P}^{2} $. Tenemos que 
\[L_{1}^{*}= [1:-3:2], \quad L_{2}^{*} = [5:-4:-3] .\]
Tenemos que $\displaystyle P^{*} $ es la recta que pasa por $\displaystyle L_{1}^{*} $ y $\displaystyle L_{2}^{*} $. Así, 
\[P = \left\{ [x_{0}:x_{1}:x_{2}] \; : \; \begin{vmatrix} x_{0} & 1 & 5 \\ x_{1} & -3 & - 4 \\ x_{2} & 2 & - 3 \end{vmatrix} = 0\right\} = \left\{ 17x_{0}+13x_{1}+11x_{2} = 0\right\}  .\]
Así, nos queda que $\displaystyle P = \left(P^{*}\right)^{*} = [17:13:11] $.
\end{eg}
\begin{observation}
En general, si $\displaystyle \mathcal{R} $ y $\displaystyle \mathcal{R}^{*} $ son referencias duales y 
\[X = 
\begin{cases}
a_{10}x_{0} + \cdots + a_{1n}x_{n} = 0 \\ 
\vdots \\ 
a_{n-d,0}x_{0}+\cdots + a_{n-d,n}x_{n} = 0
\end{cases}
,\]
es una variedad de dimensión $\displaystyle d $ de $\displaystyle \mathbb{P}\left(V\right) $ en la referencia $\displaystyle \mathcal{R} $, tenemos que 
\[\hat{X} = \left\{ \left(x_{0}, \ldots, x_{n}\right)_{\mathcal{B}} \; : \; \begin{pmatrix} a_{10} & \cdots & a_{1n} \\
\vdots & & \vdots \\
a_{n-d,0} & \cdots & a_{n-d, n}\end{pmatrix}\begin{pmatrix} x_{0} \\ \vdots \\ x_{n} \end{pmatrix} = \begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix}\right\}  .\]
Así, tendremos que 
\[\hat{X}^{\perp} = L\left(a_{10}\phi_{0} + \cdots + a_{1n}\phi_{n}, \ldots, a_{n-d,0}\phi_{0}+\cdots + a_{n-d,n}\phi_{n}\right).\]
Por tanto, 
\[X^{*} = \left\{ [x_{0}: \cdots : x_{n}]_{\mathcal{R}^{*}} \; : \; \begin{pmatrix} x_{0} \\ \vdots \\ x_{n} \end{pmatrix} = \begin{pmatrix} a_{10} & \cdots & a_{n-d,0} \\
\vdots & & \vdots \\
a_{1,n} & \cdots & a_{n-d, n}\end{pmatrix}\begin{pmatrix} \lambda_{1} \\ \vdots \\ \lambda_{n-d} \end{pmatrix}, \; \lambda_{1}, \ldots, \lambda_{n-d} \in \K\right\}  .\]
\end{observation}
\begin{eg}[Dual de un cubo]
	Consideremos en $\displaystyle \R^{3} $ el cubo de vértices $\displaystyle \left(\pm1, \pm1, \pm1\right) $. Podemos situar $\displaystyle \R^{3} $ dentro de un espacio proyectivo: $\displaystyle \R^{3} = \mathbb{P}^{3}/ \left\{ x_{0} = 0\right\}  $, es decir, 
	\[ \left(x_{1}, x_{2}, x_{3}\right) \to [1:x_{1}:x_{2}:x_{3}] .\]
	Consideremos la variedad $\displaystyle S = \left\{ x_{3}=1\right\}  $, es decir, la cara superior del cubo. Tenemos que $\displaystyle \overline{S} = \left\{ x_{3} = x_{0}\right\}  $ y
	\[\overline{S}^{*} = [1:0:0:-1] .\]
	Consideremos ahora un vértice del cubo, por ejemplo $\displaystyle P = \left(1,1,1\right) $. Tenemos que $\displaystyle \overline{P} = [1:1:1:1] $ y 
	\[\overline{P} = 
	\begin{cases}
	x_{0} = x_{1} \\
	x_{0} = x_{2} \\ 
	x_{0} = x_{3}
	\end{cases}
	.\]
	Así, tenemos que podemos calcular $\displaystyle \overline{P}^{*} $ de la siguiente forma:
	\[
	\begin{split}
		\overline{P}^{*} = & \mathbb{P}\left(L\left(\left(1,0,0,-1\right), \left(1,-1,0,0\right), \left(1,0,-1,0\right)\right)\right) \\
		= & \left\{ \begin{vmatrix} x_{0} & 1 & 1 & 1 \\ x_{1} & 0 & -1 & 0 \\ x_{2} & 0 & 0 & -1\\ x_{3} & -1 & 0 & 0 \end{vmatrix} = 0\right\}  = \left\{ x_{0}+x_{1}+x_{2}+x_{3}= 0\right\}  .
	\end{split}
	\]
	Consideremos ahora la recta $\displaystyle l = \left\{ x_{3}=1, x_{1}=1\right\}  $. Tenemos que 
	\[\overline{l} = 
	\begin{cases}
	x_{3}= x_{0} \\ 
	x_{1}= x_{0}
	\end{cases}
	.\]
Así, nos queda que su dual será
\[
\begin{split}
	\overline{l}^{*} = & \mathbb{P}\left(L\left(\left(1,0,0,-1\right), \left(1, -1, 0, 0\right)\right)\right) \\
	= & \left\{ [x_{0}:x_{1}:x_{2}:x_{3}] \; : \; \ran\begin{pmatrix} x_{0} & 1 & 1 \\ x_{1} & 0 & - 1 \\ x_{2} & 0 & 0 \\ x_{3} & -1 & 0 \end{pmatrix}=2\right\} = \left\{ x_{2} = 0, \; x_{0}+x_{1}+x_{3}=0\right\} .
\end{split}
\]
Ahora, podemos volver a $\displaystyle \R^{3} $ restringiendo las variedades duales a $\displaystyle \mathbb{P}^{3}/ \left\{ x_{0} = 0\right\}  $. 
\end{eg}
\begin{definition}[Haz de hiperplanos]
Sea $\displaystyle X \subset \mathbb{P}\left(V\right) $ una variedad con $\displaystyle \dim X = \dim\mathbb{P}\left(V\right) -2 $. El conjunto 
\[h\left(X\right)= \left\{ H \; \text{hiperplano} \; : \; X \subset H\right\}  ,\]
es el \textbf{haz de hiperplanos} con base $\displaystyle X $.
\end{definition}
\begin{eg}
En $\displaystyle \mathbb{P}^{2} $ sea $\displaystyle X $ un punto. Tenemos que $\displaystyle h\left(X\right) $ es el conjunto de rectas que pasan por $\displaystyle X $. Análogamente, en $\displaystyle \mathbb{P}^{3} $ si $\displaystyle X $ es una recta, tenemos que $\displaystyle h\left(X\right) $ es el conjunto de los planos que continenen a $\displaystyle X $. 
\end{eg}
\begin{observation}
Sea $\displaystyle X \subset \mathbb{P}\left(V\right) $ con $\displaystyle \dim X = \dim \mathbb{P}\left(V\right)-2 $. Tenemos que 
\[\dim X^{*} = \dim\mathbb{P}\left(V\right)-\dim X - 1 = \dim \mathbb{P}\left(V\right)-\dim\mathbb{P}\left(V\right)+2-1 = 1 .\]
Por tanto, $\displaystyle X^{*} $ es una recta de $\displaystyle \mathbb{P}\left(V^{*}\right) $. Además, tenemos que 
\[ X^{*}= \mathbb{P}\left(\hat{X}^{\perp }\right) = \mathbb{P}\left( \left\{ \omega \in \Hom\left(V, \K\right) \; : \; \omega\left(x\right) = 0, \; \forall x \in \hat{X}\right\} \right) = h\left(X\right).\]
\end{observation}
\section{Aplicaciones duales}
Sea $\displaystyle \mathcal{B} $ una base de $\displaystyle V $ y $\displaystyle \mathcal{B}' $ una base de $\displaystyle V' $. Consideremos $\displaystyle \mathcal{B}^{*} $ y $\displaystyle \mathcal{B}'^{*} $ las bases duales de las anteriores, respectivamente. Dada $\displaystyle f : V \to V' $ lineal, definimos la \textbf{aplicación lineal dual} de la siguiente forma:
\[f^{*} : V'^{*} \to V^{*} : \omega \in \Hom\left(V', \K\right) \to \omega\circ f \in \Hom\left(V, \K\right) .\]
Sean $\displaystyle \mathcal{B} = \left\{ v_{1}, \ldots, v_{n}\right\}  $, $\displaystyle \mathcal{B}' = \left\{ u_{1}, \ldots, u_{m}\right\}  $, $\displaystyle \mathcal{B}^{*} = \left\{ \phi_{1}, \ldots, \phi_{n}\right\}  $ y $\displaystyle \mathcal{B}'^{*} = \left\{ \psi_{1}, \ldots, \psi_{m}\right\}  $. Tenemos que 
\[f\left(v_{i}\right)=\sum^{m}_{k=1}a_{ki}u_{k}, \quad f^{*}\left(\psi{i}\right) = \sum^{n}_{k = 1}b_{ki}\phi_{k} .\]
Ahora, tenemos que 
\[a_{ij} = \psi_{i}\left(f\left(v_{j}\right)\right) = \psi_{i}\left(\sum^{m}_{k = 1}a_{kj}u_{k}\right) = f^{*}\left(\psi_{i}\right)\left(v_{j}\right) = \left(\sum^{n}_{k = 1}b_{ki}\phi_{k}\right)\left(v_{j}\right) = b_{ji} .\]
Por tanto, tenemos que  
\[\boxed{ \mathcal{M}_{\mathcal{B}^{*}\mathcal{B}'^{*}}\left(f^{*}\right) = \left(\mathcal{M}_{\mathcal{B}\mathcal{B}'}\left(f\right)\right)^{T}.} \]

\begin{lema}
Sean $\displaystyle f : V \to V' $ y $\displaystyle g : V' \to V'' $ duales. Entonces
\[\left(g\circ f\right)^{*} = f^{*}\circ g^{*} .\]
\end{lema}
\begin{proof}
Sea $\displaystyle \omega \in \Hom\left(V'', \K\right) $, entonces
\[\left(g\circ f\right)^{*}\left(\omega \right) = \omega \circ \left(g \circ f\right) = f^{*} \left(\omega \circ g\right) = f^{*} \circ g^{*} \left(\omega \right) .\]
\end{proof}
\begin{definition}[Aplicación proyectiva dual]
Dada una aplicación proyectiva $\displaystyle f : \mathbb{P}\left(V\right) \to \mathbb{P}\left(V'\right) $, con aplicación lineal asociada $\displaystyle \hat{f} : V \to V' $, definimos su \textbf{aplicación dual} como
\[ f^{*} : \mathbb{P}\left(V'^{*}\right) \to \mathbb{P}\left(V^{*}\right) : [\omega] \to [\hat{f}^{*}\left(\omega\right)] = [\omega\circ \hat{f}].\]
\end{definition}
\begin{observation}
Como $\displaystyle \left(\lambda \hat{f}\right)^{*} = \lambda \hat{f}^{*} $, $\displaystyle \forall \lambda \in \K $, tenemos que $\displaystyle f^{*} $ está bien definido. Además, $\displaystyle Z\left(f^{*}\right) = \left(\Imagen\left(f\right)\right)^{*} $. En efecto, tenemos que 
\[
\begin{split}
	Z\left(f^{*}\right) = & \mathbb{P}\left(\Ker\left(\hat{f}^{*}\right)\right) = \mathbb{P}\left( \left\{ \omega \in \Hom\left(V', \K\right) \; : \; \omega \circ \hat{f} = 0\right\} \right) \\
	= & \mathbb{P}\left( \left\{ \omega \in \Hom\left(V', \K\right) \; : \; \omega\left(x\right) = 0, \; \forall x \in \Imagen\left(\hat{f}\right)\right\} \right) = \mathbb{P}\left(\Imagen\left(\hat{f}\right)^{\perp }\right) = \Imagen\left(f\right)^{*}.
\end{split}
\]
\end{observation}
\begin{lema}
Consideremos $\displaystyle f : \mathbb{P}\left(V\right) \to \mathbb{P}\left(V'\right) $ y $\displaystyle g : \mathbb{P}\left(V'\right)\to \mathbb{P}\left(V''\right) $. Entonces, 
\begin{enumerate}
\item $\displaystyle \left(g\circ f\right)^{*} = f^{*} \circ g^{*} $.
\item $\displaystyle f^{*} $ es inyectiva $\displaystyle \iff  $ $\displaystyle f $ es sobreyectiva. 
\item $\displaystyle f^{*} $ es sobreyectiva $\displaystyle \iff  $ $\displaystyle f $ es inyectiva. 
\item $\displaystyle f^{*} $ es biyectiva $\displaystyle \iff  $ $\displaystyle f $ es biyectiva. Además, $\displaystyle \left(f^{-1}\right)^{*} = \left(f^{*}\right)^{-1} $. 
\end{enumerate}
\end{lema}
\begin{proof}
\begin{enumerate}
\item Es consecuencia de que $\displaystyle \left(g\circ f\right)^{*} = f^{*}\circ g^{*} $.
\item Es consecuencia de que $\displaystyle f^{*} $ es inyectiva si y solo si $\displaystyle \hat{f}^{*} $ también lo es, y de que $\displaystyle Z\left(f^{*}\right) = \emptyset $ si y solo si $\displaystyle f $ es suprayectiva. 
\item Con Ancochea fue demostrado para espacios vectoriales, de ahí es fácil extenderlo al espacio proyectivo. 
\item La primera parte es consecuencia de los dos apartados anteriores. Por otro lado
	\[\left(\widehat{f^{-1}}\right)^{*} = \left(\hat{f}^{-1}\right)^{*} = \left(\hat{f}^{*}\right)^{-1} .\]	
La segunda igualdad ha sido demostrada por Ancochea el año pasado.
\end{enumerate}
\end{proof}
\begin{observation}
Sea $\displaystyle f : \mathbb{P}^{n} \to \mathbb{P}^{n}' $ una homografía y $\displaystyle A \subset \mathbb{P}^{n} $, $\displaystyle B \subset \mathbb{P}^{n}' $ variedades tales que $\displaystyle f\left(A\right) = B $. Entonces, es cierto que 
\[\boxed{f^{*}\left(B^{*}\right) = A^{*}.} \]
En efecto, si $\displaystyle \omega \in f^{*}\left(B^{*}\right) $, tenemos que existe $\displaystyle \lambda \in B^{\perp } $ tal que $\displaystyle \omega = \lambda \circ f $. Así, 
\[\omega\left(A\right) = \lambda \circ f \left(A\right) = \lambda\left(f\left(A\right)\right) = \lambda\left(B\right) = \left\{ 0\right\}  .\]
Por tanto, $\displaystyle \omega \in A^{\perp } $, por lo que $\displaystyle f^{*}\left(B^{*}\right) \subset A^{*} $. Como $\displaystyle f $ es biyectiva, tenemos que $\displaystyle f^{*} $ es biyectiva. Como $\displaystyle \dim A = \dim B $, tendremos que $\displaystyle \dim A^{\perp } = \dim B^{\perp } $, por lo que $\displaystyle \dim f^{*}\left(B^{\perp}\right)= \dim A^{\perp } $ y en consecuencia $\displaystyle f^{*}\left(B^{\perp }\right)=A^{\perp } $. 
\end{observation}

\section{Variedades invariantes por homografías}

\begin{definition}[Variedad invariante]
Sea $\displaystyle f : \mathbb{P}\left(V\right) \to \mathbb{P}\left(V\right) $ una homografía. Se dice que $\displaystyle X \subset \mathbb{P}\left(V\right) $ es una \textbf{variedad invariante por} $\displaystyle f $ si $\displaystyle f\left(X\right) \subset X $ \footnote{Esto es equivalente a que $\displaystyle f\left(X\right) = X $ puesto que $\displaystyle f $ es una homografía. En efecto, si $\displaystyle f\left(X\right)\subset X $ y $\displaystyle \dim X = \dim f\left(X\right) $ está claro que $\displaystyle X = f\left(X\right) $.}.
\end{definition} 
\subsection*{Puntos fijos}
Un punto $\displaystyle P \in \mathbb{P}\left(V\right) $ es fijo si $\displaystyle f\left(P\right) = P $, que es cierto si y solo si 
\[P = [x_{0}:\cdots:x_{n}], \; \exists \lambda \in \K^{*}, \lambda \begin{pmatrix} x_{0} \\ \vdots \\ x_{n} \end{pmatrix} = M\left(f\right) \begin{pmatrix} x_{0} \\ \vdots \\ x_{n} \end{pmatrix} .\]
Esto es cierto si y solo si $\displaystyle P = [v] $ es un autovector para $\displaystyle \lambda \neq 0 $. Así, tendremos que $\displaystyle \lambda  $ es raíz del polinomio
\[p\left(t\right) = \det\left(M_{\mathcal{B}}\left(\hat{f}\right)-t I\right) .\]
Dependiendo de $\displaystyle \K $ puede haber puntos fijos o no. Por ejemplo, si $\displaystyle \K = \C $, el polinomio característico de $\displaystyle \hat{f} $ siempre tiene raíces, pero si $\displaystyle \K = \Q $ o $\displaystyle \K = \R $ no siempre tiene raíces. Fijado $\displaystyle \lambda  $ raíz de $\displaystyle p\left(t\right) $, tomamos
\[\hat{X}_{\lambda} = \Ker\left(\hat{f}-\lambda id\right), \; X_{\lambda }= \mathbb{P}\left(\hat{X}_{\lambda }\right) .\]
Así, tenemos que $\displaystyle X_{\lambda } $ es una variedad de puntos fijos de $\displaystyle f $. 
\subsection*{Hiperplanos invariantes}
Un hiperplano $\displaystyle H = \left\{ b_{0}x_{0}+\cdots + b_{n}x_{n} = 0\right\}  $ es invariante para $\displaystyle f $ si y solo si 
\[f\left(H\right) \subset H \iff f^{*}\left(H^{*}\right) \supset H^{*} \iff f^{*}\left([b_{0}: \cdots : b_{n}]\right) = [b_{0}: \cdots : b_{n}].\]
Esto es cierto si y solo si existe $\displaystyle \lambda \in \K^{*} $ tal que 
\[\lambda \begin{pmatrix} b_{0} \\ \vdots \\ b_{n} \end{pmatrix} = M_{\mathcal{B}^{*}}\left(\hat{f}^{*}\right)\begin{pmatrix} b_{0} \\ \vdots \\ b_{n} \end{pmatrix} \iff \lambda \begin{pmatrix} b_{0} \\ \vdots \\ b_{n} \end{pmatrix} = M_{\mathcal{B}}\left(\hat{f}\right)^{T}\begin{pmatrix} b_{0} \\ \vdots \\ b_{n} \end{pmatrix} .\]
Esto es cierto si y solo si 
\[\begin{pmatrix} b_{0} \\ \vdots \\ b_{n} \end{pmatrix} \in \Ker\left(M_{\mathcal{B}}\left(\hat{f}\right)^{T} - \lambda id \right) .\]
Esto es cierto si y solo si $\displaystyle \lambda  $ es raíz del polinomio característico de $\displaystyle M_{\mathcal{B}}\left(\hat{f}\right)^{T} $, que coincide con el polinomio característico de $\displaystyle \hat{f} $. Si tomamos 
\[\hat{Y}_{\lambda } = \Ker\left(M_{\mathcal{B}}\left(\hat{f}\right)^{T}-\lambda id\right) , \]
tenemos que 
\[\mathbb{P}\left(\hat{Y}_{\lambda }\right)^{*} = \left\{ b_{0}x_{0} + \cdots + b_{n}x_{n} = 0 \; : \; \left(b_{0}, \ldots, b_{n}\right) \in \hat{Y}_{\lambda}- \left\{ 0\right\} \right\}  ,\]
que es una familia de hiperplanos invariantes para $\displaystyle f $. 
\subsection*{Rectas invariantes}
\begin{prop}
Sea $\displaystyle f : \mathbb{P}^{n} \to \mathbb{P}^{n} $ una homografía y $\displaystyle L $ una recta de $\displaystyle \mathbb{P}^{n} $. Entonces, son equivalentes:
\begin{description}
\item[(i)] $\displaystyle L $ es una recta invariante para $\displaystyle f $. 
\item[(ii)] $\displaystyle L \subset \Fix\left(f\right) $ o existe $\displaystyle P \in L/\Fix\left(f\right) $ tal que $\displaystyle f^{2}\left(P\right) \in V\left( \left\{ P, f\left(P\right)\right\}  \right) = L $. 
\end{description}
\end{prop}
\begin{proof}
\begin{description}
	\item[$\displaystyle \Rightarrow $] Supongamos que $\displaystyle L $ es una recta invariante por $\displaystyle f $ y $\displaystyle L \subsetneq \Fix\left(f\right) $. Entonces, existe $\displaystyle P \in L$ tal que $\displaystyle f\left(P\right) \neq P $. Como $\displaystyle L $ es invariante, tenemos que $\displaystyle f\left(P\right) \in L $, por lo que $\displaystyle L = V\left( \left\{ P, f\left(P\right)\right\} \right) $. 
		Como $\displaystyle f\left(P\right) \in L $ y $\displaystyle L $ es invariante, debe ser que $\displaystyle f^{2}\left(P\right) \in L $. 
	\item[$\displaystyle \Leftarrow $] Si $\displaystyle L \subset \Fix\left(f\right) $ no hay nada que demostrar. Supongamos que $\displaystyle L \subsetneq \Fix\left(f\right) $ y que existe $\displaystyle P \in L/\Fix\left(f\right) $ tal que $\displaystyle f^{2}\left(P\right) \in V\left( \left\{ P, f\left(P\right)\right\} \right) = L $. Tenemos que para $\displaystyle Q \in L $,
		\[f\left(Q\right) \in f\left(L\right) = f\left(V\left( \left\{ P, f\left(P\right)\right\} \right)\right) = V\left( \left\{ f\left(P\right), f^{2}\left(P\right)\right\} \right) = L .\]
		Así, tenemos que $\displaystyle L $ es invariante. 
\end{description}
\end{proof}
\begin{eg}
	Calcular rectas invariantes para homografías involutivas es muy sencillo. En efecto si $\displaystyle L \subsetneq \Fix\left(f\right) $, cogemos $\displaystyle P \in L $ con $\displaystyle f\left(P\right) \neq P $, entonces $\displaystyle f^{2}\left(P\right) = P \in V \left( \left\{ P, f\left(P\right)\right\} \right) $ y tomamos $\displaystyle L = V\left( \left\{ P, f\left(P\right)\right\} \right) $. \\
	Así, las rectas invariantes de una homografía involutiva son las rectas de puntos fijos y las que unen un punto no fijo con su imagen. 
\end{eg}
\begin{observation}
Dada una homografía $\displaystyle f : \mathbb{P}^{3} \to \mathbb{P}^{3} $, sabemos que la búsqueda de puntos fijos e hiperplanos invariantes se reduce a buscar subespacios de autovectores. Veámos cómo proceder para calcular las rectas invariantes. 
\begin{itemize}
	\item Cada par de puntos fijos $\displaystyle P $ y $\displaystyle Q $ determina una recta invariatne $\displaystyle V\left( \left\{ P,Q\right\} \right) $ y cada par de hiperplanos invariantes $\displaystyle H_{1} $ y $\displaystyle H_{2} $ determina una recta invariante $\displaystyle H_{1} \cap H_{2} $. 
	\item La restricción de $\displaystyle f $ a cada hiperplano invariante $\displaystyle H $ es una homografía $\displaystyle f|_{H} : H \to H $, cuyas rectas invariantes se calculan resolviendo un sistema de ecuaciones lineales por ser hiperplanos de $\displaystyle H $.
	\item Por último, podemos utilizar la proposición anterior para calcular las restantes rectas invariantes o confirmar su defecto si las anteriores eran todas. 
\end{itemize}
\end{observation}
\begin{eg}[Rectas invariantes por homologías]
Se dice que una homografía $\displaystyle f : \mathbb{P}^{n} \to \mathbb{P}^{n} $ es una homología si el conjunto de puntos fijos es igual a un hiperplano de puntos fijos, $\displaystyle H $, más un punto fijo exterior a este hiperplano, $\displaystyle P $. \\
En este caso las únicas rectas invariantes son 
\begin{itemize}
\item las rectas contenidas en $\displaystyle H $.
\item las rectas que pasan por $\displaystyle P $, puesto que cortan a $\displaystyle H $ y son invariantes por ser la unión de dos puntos fijos. 
\end{itemize}
Tenemos que $\displaystyle \mathbb{A} = \mathbb{P}^{n} / H $ es un espacio afín y, como $\displaystyle f |_{H}= id $ y $\displaystyle f|_{\mathbb{A}} $ tiene un único punto fijo, $\displaystyle f|_{\mathbb{A}} $ es una homotecia. \\
Supongamos que hay una recta invariante, $\displaystyle \ell $, no contenida en $\displaystyle H $ y que no pasa por $\displaystyle P $. Sea $\displaystyle Q \in \ell/H $ con $\displaystyle Q \neq P $, podemos hacer dos observaciones:
\begin{itemize}
\item Como $\displaystyle \ell $ es invariante, $\displaystyle f\left(Q\right) \in \ell $.
\item Como $\displaystyle f|_{\mathbb{A}} $ es una homotecia, debe ser que $\displaystyle f\left(Q\right) \in V\left( \left\{ P, Q\right\} \right) $.
\end{itemize}
Así, tenemos que 
\[f\left(Q\right) \in \ell \cap V\left( \left\{ P,Q\right\} \right) = \left\{ Q\right\}  .\]
Tenemos que $\displaystyle f\left(Q\right) = Q $ y como no hay más puntos invariantes que $\displaystyle P $, esto es una contradicción. 
\end{eg}

\subsection*{Otras subvariedades invariantes}

\begin{lema}
Sean $\displaystyle X_{1}, X_{2} $ variedades invariantes para una homografía $\displaystyle f : \mathbb{P}\left(V\right)\to \mathbb{P}\left(V\right) $ y $\displaystyle \dim\mathbb{P}\left(V\right) < \infty $. Entonces, $\displaystyle X_{1} \cap X_{2} $ y $\displaystyle X_{1} + X_{2} $ son invariantes para $\displaystyle f $.
\end{lema}
\begin{proof}
Tenemos que $\displaystyle f\left(X_{1}\right) \subset X_{1} $ y $\displaystyle f\left(X_{2}\right) \subset X_{2} $. Así, tenemos que 
\[f\left(X_{1} \cap X_{2}\right) \subset f\left(X_{1}\right) \cap f\left(X_{2}\right) \subset X_{1} \cap X_{2} .\]
Por tanto, $\displaystyle X_{1} \cap X_{2} $ es invariante. Ahora, tenemos que $\displaystyle X_{1} + X_{2} = V\left(X_{1} \cup X_{2}\right) $. Así, tenemos que 
\[f\left(X_{1}\right)\cup f\left(X_{2}\right) \subset f\left(X_{1}\right) + f\left(X_{2}\right), \quad f\left(X_{1}\right)\cup f\left(X_{2}\right) \subset f\left(X_{1}+X_{2}\right) .\]
Así, tenemos que $\displaystyle f\left(X_{1}\right)+f\left(X_{2}\right) \subset f\left(X_{1} + X_{2}\right) $. Por ser homografía, tenemos que $\displaystyle f\left(X_{1}\right) = X_{1} $ y $\displaystyle f\left(X_{2}\right) = X_{2} $. Así, tenemos que 
\[X_{1} + X_{2} \subset f\left(X_{1} + X_{2}\right) .\]
Por ser $\displaystyle f $ homografía tenemos que $\displaystyle \dim\left(X_{1} + X_{2}\right)= \dim f\left(X_{1} + X_{2}\right) $, por lo que $\displaystyle X_{1} + X_{2} = f\left(X_{1} + X_{2}\right) $. 
\end{proof}

\begin{eg}
Consideremos  
\[  f : \mathbb{P}^{3} \to \mathbb{P}^{3} : [x_{0}:x_{1}:x_{2}:x_{3}] \to [x_{0}+x_{1}:x_{1}+x_{2}:x_{2}+x_{3}:2x_{3}].\]
Tenemos que
\[M\left(f\right) = \begin{pmatrix} 1 & 1 & & \\ & 1 & 1 & \\ & & 1 & 1 \\ & & & 2 \end{pmatrix} .\]
Tenemos que el polinomio característico será $\displaystyle P_{M}\left(t\right) = \det\left(M - t id\right)=\left(1-t\right)^{3}\left(2-t\right) $, por lo que los autovalores son $\displaystyle \lambda \in \left\{ 1,2\right\}  $. 
\begin{itemize}
\item Los puntos fijos para $\displaystyle \lambda = 1 $ son:
	\[\left(M - \lambda I\right)\begin{pmatrix} x_{0} \\ \vdots \\ x_{3} \end{pmatrix}=\begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix} \Rightarrow 
	\begin{cases}
	x_{0} = 0 \\ 
	x_{1} = 0 \\
	x_{2} = 0 \\
	x_{3} = 0
	\end{cases}
.\]
Así, tenemos que la variedad de los puntos fijos para $\displaystyle \lambda = 1 $ es $\displaystyle X_{1} = [1:0:0:0] $. 
\item Los puntos fijos para $\displaystyle \lambda = 2 $ serán 
	\[\left(M - 2 I\right) \begin{pmatrix} x_{0} \\ \vdots \\ x_{3} \end{pmatrix}= \begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix} \Rightarrow 
\begin{cases}
-x_{0}+x_{1} = 0 \\
-x_{1} + x_{2} = 0 \\
-x_{2}+x_{3} = 0
\end{cases}
.\]
Así, la variedad de puntos fijos para $\displaystyle \lambda = 2 $ será $\displaystyle X_{2} = [1:1:1:1] $. 
\item Los hiperplanos invariantes para $\displaystyle \lambda = 1 $ será:
	\[ \left(M^{t}-I\right)\begin{pmatrix} b_{0} \\ \vdots \\ b_{3} \end{pmatrix}=\begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix} \Rightarrow 
\begin{cases}
b_{0} = 0 \\
b_{1} = 0 \\
b_{2}+b_{3}=0
\end{cases}
.\]
Así, nuestra familia de hiperplanos invariantes para $\displaystyle \lambda = 1 $ son $\displaystyle H = \left\{ x_{2}-x_{3} = 0\right\} = [0 : 0 : 1 : - 1]^{*} $. 
\item Los hiperplanos invariantes para $\displaystyle \lambda = 2 $ serán:
	\[\left(M^{t}-2I\right)\begin{pmatrix} b_{0} \\ \vdots \\ b_{3} \end{pmatrix}=\begin{pmatrix} 0 \\ \vdots \\ 0 \end{pmatrix} \Rightarrow
\begin{cases}
-b_{0} = 0 \\
b_{0}-b_{1} = 0 \\
b_{1}-b_{2} = 0 \\
b_{2}=0
\end{cases}
.\]
Así, $\displaystyle H = \left\{ x_{3}=0\right\} = [0:0:0:1] ^{*}$ es nuestra familia de hiperplanos invariantes para $\displaystyle \lambda = 2 $. 
\item Calculamos las rectas invariantes. Sabemos que la recta que pasan por los dos puntos fijos es una recta invariante. Así, obtenemos
	\[l_{1} = \left\{ \left[1:0:0:0\right] \right\} + \left\{ \left[1:1:1:1\right] \right\}  .\]
	Análogamente la recta que resulta de la intersección de los dos hiperplanos es otra recta invariante. Así, obtenemos
	\[l_{2} = 
	\begin{cases}
	x_{2}-x_{3} = 0 \\
	x_{3} = 0
	\end{cases}
	.\]
	La pregunta es, hay más rectas invariantes? Sea $\displaystyle l $ una recta invariante. Si $\displaystyle [1:0:0:0] $ y $\displaystyle [1:1:1:1] $ están en $\displaystyle l $, tenemos que $\displaystyle l = l_{1} $. Por otro lado, si $\displaystyle [1:0:0:0] \in l$ y $\displaystyle [1:1:1:1] \not\in l $, podemos considerar la variedad
	\[X = \left\{ [1:1:1:1]\right\} +l ,\]
	que es una variedad invariante. Así, tenemos que 
	\[\dim X = \dim \left\{ [1:1:1:1]\right\} +\dim l - \dim\left(l \cap \left\{ [1:1:1:1]\right\} \right) = 2 .\]
	Por tanto tenemos que $\displaystyle X $ es un hiperplano invariante, por lo que debe ser que $\displaystyle X \in \left\{ H_{1}, H_{2}\right\}  $. En este caso tenemos que $\displaystyle X = H_{1} $. Tenemos que $\displaystyle l \cap H_{2} $ es una variedad invariante, por lo que
	\[\dim l \cap H_{2} = \dim l + \dim H_{2} - \dim\left(l + H_{2}\right) \geq 1 + 2 - 3 = 0 .\]
	Por tanto, tenemos que $\displaystyle l \cap H_{2} \neq \emptyset $. Si $\displaystyle \dim\left(l \cap H_{2}\right) = 1 $, tenemos que $\displaystyle l \subset H_{2} $, pero como $\displaystyle l \subset H_{1} $, tenemos que $\displaystyle l = l_{2} $. Por otro lado, si $\displaystyle \dim\left(l \cap H_{2}\right)= 0 $, tenemos que $\displaystyle l \cap H_{2} = [1:0:0:0] $. \\
	Sabemos que si $\displaystyle l $ existe, entonces $\displaystyle l \subset H $ y $\displaystyle l \cap H_{2} = [1:0:0:0] $. Sea $\displaystyle P = [a:b:c:d] \in l $ con $\displaystyle P \neq [1:0:0:0] $. Como $\displaystyle P \in H_{1} $ tenemos que $\displaystyle P = [a : b : c :c] $. Tenemos que 
	\[f\left(P\right) = [a+ b : b + c : 2c : 2c] \in l .\]
Nuevamente, 
\[f^{2}\left(P\right) = \left[a + 2b + c : b + 3c : 4c : 4c\right] .\]
Tenemos que $\displaystyle \left(a,b,c,c\right), \left(a+b, b+c, 2c, 2c\right), \left(a+2b+c, b+3c, 4c, 4c\right) \in \hat{l} $ y $\displaystyle \dim\hat{l} = 2 $, por lo que 
\[
\begin{split}
	2 = & \ran\begin{pmatrix} a & b & c & c \\ a+b & a+c & 2c & 2c \\ a+2b+c & a+3c & 4c & 4c \end{pmatrix}=\ran\begin{pmatrix} a & b & c & c \\ b & c & c & c \\ 2b + c & 3c & 3c & 3c \end{pmatrix} \\
	= & \ran\begin{pmatrix} a & b & c \\ b & c & c \\ c & c & c \end{pmatrix}.
\end{split}
\]
Si $\displaystyle c = 0 $, tenemos que 
\[\ran\begin{pmatrix} a & b & 0 \\ b & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix}= 2 \Rightarrow b \neq 0 .\]
Así, tenemos que $\displaystyle P = [a:1:0:0] $. Así, tenemos que $\displaystyle l = P + \left\{ [1:0:0:0]\right\}  $, por lo que 
\[\hat{l}= L\left( \left\{ \left(1,0,0,0\right), \left(a,1,0,0\right)\right\} \right) = L\left( \left\{ \left(0,1,0,0\right), \left(1,0,0,0\right)\right\} \right) .\]
Así, hemos obtenido que $\displaystyle l = l_{2} $. Esto es una contradicción, puesto que habíamos dicho que $\displaystyle l \cap H_{2} $ era un punto. Por tanto, supongamos ahora que $\displaystyle c \neq 0 $, podemos suponer $\displaystyle c = 1 $ y tenemos que
\[2 = \ran\begin{pmatrix} a & b & 1 \\ b & 1 & 1 \\ 1 & 1 & 1 \end{pmatrix} \Rightarrow \begin{vmatrix} a & b & 1 \\ b & 1 & 1 \\ 1 & 1 & 1 \end{vmatrix} = -\left(b-1\right)^{2} = 0.\]
Así, obtenemos que $\displaystyle b=1 $ y por tanto $\displaystyle P = [a : 1 : 1 : 1] $. Así, como $\displaystyle l = P + \left\{ [1:0:0:0]\right\}  $, tenemos que 
\[\hat{l} = L\left( \left\{ \left(a,1,1,1\right), \left(1,0,0,0\right)\right\} \right) .\]
Así, tenemos que $\displaystyle \left(1,1,1,1\right) \in l $, por lo que $\displaystyle l = l_{1} $, que es una contradicción puesto que habíamos supuesto que $\displaystyle [1:1:1:1]\not\in l $. Por tanto, no existe la recta con las características que hemos pedido. \\ 
Supongamos ahora que $\displaystyle [1:0:0:0] \in l$ y $\displaystyle [1:1:1:1] \in l $. Tenemos que $\displaystyle l \cap H_{2} $ es una variedad invariante. Haciendo el mismo argumento que antes, tenemos que 
\[\dim\left(l \cap H_{2}\right) = \dim l + \dim H_{2}-\dim\left(l + H_{2}\right) \geq 0 .\]
Si $\displaystyle l \subset H_{2} $, tenemos que $\displaystyle [1:1:1:1] \in H_{2} $, que no es posible. Si $\displaystyle l \cap H_{2} $ es un punto, tenemos que es un punto fijo por lo que debe ser que $\displaystyle l \cap H_{2} = [1:0:0:0] $, por lo que $\displaystyle [1:0:0:0] \in l $, que es una contradicción. Así, no existe una recta invariante con estas características. \\
Finalmente, si $\displaystyle [1:0:0:0] \not\in l$ y $\displaystyle [1:1:1:1] \not\in l $, tenemos que $\displaystyle l \cap H_{i} $ no es un punto fijo, por lo que debe ser que $\displaystyle l \subset H_{i} $ para $\displaystyle i = 1,2 $. Así, tenemos que $\displaystyle l = H_{1} \cap H_{2} $, que es una contradicción puesto que $\displaystyle [1:0:0:0] \in H_{1} \cap H_{2} $. 
\end{itemize}
\end{eg}
\section{Espacios afines en espacios proyectivos}
Recordamos que si $\displaystyle \mathbb{P}^{n} $ es un espacio proyctivo de dimensión $\displaystyle n $, $\displaystyle \mathbb{P}^{n} = \mathbb{P}\left(V\right) $ y $\displaystyle f : V \to \K $ lineal, entonces $\displaystyle \mathbb{P}^{n}/\mathbb{P}\left(\Ker\left(f\right)\right) $ es un espacio afín con dirección $\displaystyle \Ker\left(f\right) \subset V $. Así, podemos escribir, $\displaystyle \mathbb{P}\left(\Ker\left(f\right)\right) $ es un hiperplano $\displaystyle H $ de $\displaystyle \mathbb{P}^{n} $ y tenemos que $\displaystyle \hat{H} = \Ker\left(f\right) $. 
\begin{prop}
	Sea $\displaystyle \psi : \mathbb{P}^{n} \to \mathbb{P}^{n} $ una homografía y $\displaystyle H = \left\{ \omega = 0\right\} \footnote{Es el núcleo de una forma lineal.} $ un hiperplano invariante para $\displaystyle \psi $. Entonces $\displaystyle \psi|_{\mathbb{A}}:\mathbb{A} \to \mathbb{A} $, con $\displaystyle \mathbb{A} = \mathbb{P}^{n} / H $ es una afinidad.
\end{prop}
\begin{proof}
	Como $\displaystyle \psi\left(H\right) = H $, $\displaystyle \psi $ induce una función en el complementario de $\displaystyle H $, que es $\displaystyle \mathbb{A} $. Para ver que $\displaystyle \psi_{\mathbb{A}} $ es una afinidad basta comprobar que preserva las combinaciones afines. Sean $\displaystyle P_{0}, \ldots, P_{k} \in \mathbb{A} $ con $\displaystyle P_{i} = [v_{i}] $, $\displaystyle v_{i} \in V/ \left\{ 0\right\}  $ y $\displaystyle \omega\left(v_{i}\right)\neq 0 $, y sean $\displaystyle \lambda_{0}, \ldots, \lambda_{k} \in \K $ tales que $\displaystyle \sum^{k}_{i = 1}\lambda_{i} = 1 $. 
	Así, tenemos que
	\[
	\begin{split}
		\psi\left(\lambda_{0}P_{0}+\cdots + \lambda_{k}P_{k}\right) = & \psi\left(P_{0} + \sum^{k}_{i = 1}\lambda_{i}\overrightarrow{P_{0}P_{i}}\right) = \psi\left([v_{0}] + \sum^{k}_{ i = 1}\lambda_{i}\left(\frac{v_{i}}{\omega\left(v_{i}\right)}-\frac{v_{0}}{\omega\left(v_{0}\right)}\right)\right) \\
		= & \psi\left(\left[\frac{v_{0}}{\omega\left(v_{0}\right)}+\sum^{k}_{i = 1}\lambda_{i}\left(\frac{v_{i}}{\omega\left(v_{i}\right)}-\frac{v_{0}}{\omega\left(v_{0}\right)}\right)\right] \right) = \left[\frac{\hat{\psi}\left(v_{0}\right)}{\omega\left(v_{0}\right)} + \sum^{k}_{i = 1}\lambda_{i}\left(\frac{\hat{\psi}\left(v_{i}\right)}{\omega\left(v_{i}\right)} -\frac{\hat{\psi}\left(v_{0}\right)}{\omega\left(v_{0}\right)}\right)\right] \\
		=^{*} & \left[\frac{\hat{\psi}\left(v_{0}\right)}{C\omega\left(\hat{\psi}\left(v_{0}\right)\right)}+\sum^{k}_{i = 1}\lambda_{i}\left(\frac{\hat{\psi}\left(v_{i}\right)}{C\omega\left(\hat{\psi}\left(v_{i}\right)\right)}-\frac{\hat{\psi}\left(v_{0}\right)}{C\omega\left(\hat{\psi}\left(v_{0}\right)\right)}\right)\right] \\
		= & \left[\frac{\hat{\psi}\left(v_{0}\right)}{\omega\left(\hat{\psi}\left(v_{0}\right)\right)}+\sum^{k}_{i = 1}\lambda_{i}\left(\frac{\hat{\psi}\left(v_{i}\right)}{\omega\left(\hat{\psi}\left(v_{i}\right)\right)}-\frac{\hat{\psi}\left(v_{0}\right)}{\omega\left(\hat{\psi}\left(v_{0}\right)\right)}\right)\right] \\
		= & \left[\hat{\psi}\left(v_{0}\right)\right] +\sum^{k}_{i = 1}\lambda_{i}\overrightarrow{[\hat{\psi}\left(v_{0}\right)][\hat{\psi}\left(v_{i}\right)]} = \psi\left(P_{0}\right) + \sum^{k}_{i = 1}\lambda_{i}\overrightarrow{\psi\left(P_{0}\right)\psi\left(P_{i}\right)} \\
		= & \lambda_{0}\psi\left(P_{0}\right) + \cdots + \lambda_{k}\psi\left(P_{k}\right).
	\end{split}
	\]
Veamos que $\displaystyle * $ es cierto, es decir, veamos que $\displaystyle \Ker\left(\omega \right)= \Ker\left(\omega \circ \hat{\psi}\right) $. 
\[
\begin{split}
	v \in \Ker\left(\omega \right)/ \left\{ 0\right\} \iff & [v] \in H \iff \psi\left([v]\right)\in H \iff [\hat{\psi}\left(v\right)] \in H \\
	\iff & \hat{\psi}\left(v\right) \in \Ker\left(\omega \right) \iff \omega\left(\hat{\psi}\left(v\right)\right) = 0 \iff v \in \Ker\left(\omega \circ \hat{\psi}\right).
\end{split}
\]
Tenemos que $\displaystyle V = \Ker\left(\omega \right)\oplus L\left(u\right) $ para algún $\displaystyle u \in V $. Si $\displaystyle v \in V $, existe $\displaystyle z \in \Ker\left(\omega \right)  $ y $\displaystyle \lambda \in \K $ tal que $\displaystyle v = z + \lambda u $. Así, tenemos que 
\[\omega\left(v\right) = \omega\left(z + \lambda u\right) = \omega\left(\lambda u\right) = \lambda\omega\left(u\right) .\]
Así, tenemos que 
\[
\begin{split}
	\left(\omega\circ\hat{\psi}\right)\left(v\right)  = & \omega\left(\hat{\psi}\left(v\right)\right) = \omega\left(\hat{\psi}\left(z + \lambda u\right)\right) = \omega\left(\hat{\psi}\left(\lambda u\right)\right) = \lambda \omega\left(\hat{\psi}\left(u\right)\right).
\end{split}
\]
Así, podemos coger $\displaystyle C = \frac{\omega\left(v\right)}{\omega\left(\hat{\psi}\left(v\right)\right)} = \frac{\omega\left(u\right)}{\omega\left(\hat{\psi}\left(u\right)\right)} $.
\end{proof}
\begin{eg}
Consideremos la homografía
\[f : \mathbb{P}^{3} \to \mathbb{P}^{3} : [x_{0}:x_{1}:x_{2}:x_{3}] \to [x_{0}+x_{1}:x_{1}+x_{2}:x_{2}+x_{3}:2x_{3}] .\]
Un plano invariante es $\displaystyle H = \left\{ x_{3} = 0\right\}  $. Así, podemos considerar el espacio afín $\displaystyle \mathbb{A} = \mathbb{P}^{3} / H = \left\{ [x_{0}:x_{1}:x_{2}:1] \; : \; x_{0}, x_{1}, x_{2} \in \K\right\}  $. Buscamos ahora $\displaystyle f|_{\mathbb{A}} $. Buscamos una referencia de $\displaystyle \mathbb{A} $. Sabemos que $\displaystyle H_{2} = \left\{ x_{2}-x_{3} = 0\right\}  $ es invariante y los puntos $\displaystyle [1 : 0:0:0] $ y $\displaystyle [1:1:1:1] $ son fijos. 
Sea $\displaystyle O = [1:1:1:1] \in \mathbb{A}$, por lo que $\displaystyle f\left(O \right)= O $. Consideremos ahora los puntos,
\[ P_{1} = [1 : 0 : 1 : 1], \quad P_{2} = [0:1:1:1] \quad \text{y} \quad P_{3} = [0:0:0:1].\]
Tenemos que 
\[f\left(P_{1}\right)= [1:1:2:2] = \left[\frac{1}{2}:\frac{1}{2}:1:1\right], \quad f\left(P_{2}\right)=[1:2:2:2] = \left[\frac{1}{2}:1:1:1\right]  .\]
\[f\left(P_{3}\right) = [0:0:1:2] = \left[0:0:\frac{1}{2}:1\right] .\]
Así, podemos tomar la referencia cartesiana $\displaystyle \mathcal{R}_{C} = \left\{ O, \mathcal{B} = \left\{ \overrightarrow{OP_{1}}, \overrightarrow{OP_{2}}, \overrightarrow{OP_{3}}\right\} \right\}  $. Calculemos la matriz de $\displaystyle f|_{\mathbb{A}} $. Tenemos que 
\[\vec{f}\left(\overrightarrow{OP_{1}}\right) = \overrightarrow{f\left(O\right)f\left(P_{1}\right)}= \overrightarrow{[1:1:1:1]\left[\frac{1}{2}:\frac{1}{2}:1:1\right] } = \left(-\frac{1}{2}, -\frac{1}{2}, 0,0\right) .\]
\[\vec{f}\left(\overrightarrow{OP_{2}} \right) = \overrightarrow{f\left(O\right)f\left(P_{2}\right)} = \overrightarrow{[1:1:1:1]\left[\frac{1}{2}:1:1:1\right] } = \left(-\frac{1}{2} , 0, 0, 0\right) .\]
\[\vec{f}\left(\overrightarrow{OP_{3}}\right) = \overrightarrow{f\left(O\right)f\left(P_{2}\right)}= \overrightarrow{[1:1:1:1]\left[0:0:\frac{1}{2}:1\right] } = \left(-1,-1, -\frac{1}{2}, 0\right) .\]
Así, tenemos que 
\[\mathcal{B} = \left\{ \left(-1,0,0,0\right), \left(0, -1, 0,0\right), \left(-1,-1,-1,0\right)\right\}  .\]
En esta base, tenemos que 
\[\overrightarrow{f\left(OP_{2}\right)} = \left(\frac{1}{2}, 0, 0\right)_{\mathcal{B}}, \quad \overrightarrow{f\left(OP_{1}\right) } = \left(\frac{1}{2}, \frac{1}{2}, 0\right)_{\mathcal{B}}, \quad \overrightarrow{f\left(OP_{3}\right)} = \left(\frac{1}{2}, \frac{1}{2}, \frac{1}{2}\right)_{\mathcal{B}} .\]
Así, nos queda que la matriz de $\displaystyle f|_{\mathbb{A}} $ en la referencia $\displaystyle \mathcal{R}_{C} $ será
\[M_{\mathcal{R}_{C}}\left(f|_{\mathbb{A}}\right) = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & \frac{1}{2} & \frac{1}{2} & \frac{1}{2} \\ 0 & 0 & \frac{1}{2} & \frac{1}{2} \\ 0 & 0 & 0 & \frac{1}{2} \end{pmatrix} .\]
\end{eg}

\begin{observation}
Sea $\displaystyle X \subset \mathbb{P}^{n} $ una variedad tal que 
\[X = 
\begin{cases}
a_{00}x_{0} + \cdots + a_{0n}x_{n} = 0 \\
\vdots \\
a_{k0}x_{0} + \cdots + a_{kn}x_{n} = 0
\end{cases}
.\]
Consideremos el hiperplano $\displaystyle H = \left\{ b_{0}x_{0} + \cdots + b_{n}x_{n} = 0\right\} $ y consideremos $\displaystyle \mathbb{A} = \mathbb{P}^{n} / H $ que es un espacio afín. Tenemos que $\displaystyle X \cap \mathbb{A} $ es una variedad afín. En efecto, tenemos que 
\[\mathbb{A} = \left\{ [x_{0} : \cdots :x_{n}] \; : \; b_{0}x_{0}+ \cdots + b_{n}x_{n} = 1\right\} =  \left\{ \left( \frac{1}{b_{0}}\left(1-b_{1}x_{1}-\cdots -b_{n}x_{n}\right), x_{1}, \ldots, x_{n}\right)\right\} \subset \K^{n+1}	.\]
Así, tenemos que 
\[X \cap \mathbb{A} = 
\begin{cases}
a_{00} \frac{1}{b_{0}}\left(1-b_{1}x_{1}-\cdots -b_{n}x_{n}\right)+ \cdots + a_{n}x_{n} = 0 \\
\vdots \\
a_{k0} \frac{1}{b_{0}}\left(1-b_{1}x_{1}-\cdots -b_{n}x_{n}\right)+ \cdots + a_{k}x_{n}=0
\end{cases}
,\]
que son las ecuaciones implícitas de una variedad afín. 
\end{observation}
 \begin{eg}
	 Consideremos en $\displaystyle \mathbb{P}^{3} $ el hiperplano $\displaystyle H = \left\{ x_{0}+x_{1}+x_{2} = 0\right\}  $. Tenemos que 
	 \[ \mathbb{A} = \left\{ \left(x_{0}, x_{1}, x_{2}, x_{3}\right) \; : \; x_{0}+x_{1}+x_{2} = 1\right\}  .\]
	 Consideremos por otro lado la variedad
	 \[X = 
	 \begin{cases}
	 2x_{0} + x_{3} = 0 \\
	 2x_{1} - x_{3} = 0
	 \end{cases}
	 .\]
Así, tenemos que 
\[X \cap \mathbb{A} = 
\begin{cases}
2\left(1-x_{1}-x_{2}\right) + x_{3} = 0 \\
2x_{1}-x_{3} = 0 
\end{cases}
\Rightarrow 
\begin{cases}
-x_{1}-x_{2}+x_{3} = -2 \\
2x_{1} -x_{3} = 0
\end{cases}
.\]
 \end{eg}
\section{Completaciones proyectivas}
Sea $\displaystyle f : \mathbb{A} \to \mathbb{A} $ una afinidad con $\displaystyle \dim\mathbb{A} = n $ y $\displaystyle \mathcal{R}_{C} = \left\{ O, \mathcal{B} = \left\{ v_{1}, \ldots, v_{n}\right\} \right\}  $ una referencia cartesiana de $\displaystyle \mathbb{A} $. Para meter el espacio afín $\displaystyle \mathbb{A} $ un un espacio proyectivo consideramos la aplicación 
\[i : \mathbb{A} \to \mathbb{P}\left(\K^{n+1}\right) = \mathbb{P}^{n} : \left(x_{1}, \ldots, x_{n}\right)_{\mathcal{B}} \to \left[1:x_{1}: \cdots :x_{n}\right]  .\]
Tenemos que 
\[\Imagen\left(i\right) = \left\{ \left[1:x_{1}: \cdots : x_{n}\right]  \; : \; x_{1}, \ldots, x_{n} \in \K\right\} = \mathbb{P}^{n} / \left\{ x_{0} = 0\right\}  .\]
\begin{definition}
Se define la \textbf{completación proyectiva} de $\displaystyle f $ respecto a $\displaystyle i $ de la forma
\[\overline{f} : \mathbb{P}^{n} \to \mathbb{P}^{n} : [x_{0}: \cdots :x_{n}] \to \left[x_{0}\left(1,f\left(0, \ldots, 0\right)\right) + \left(0, \vec{f}\left(x_{1}, \ldots, x_{n}\right)\right)\right]  .\]
\end{definition}
\begin{prop}
La aplicación $\displaystyle \overline{f}:\mathbb{P}^{n} \to \mathbb{P}^{n} $ es una homografía y $\displaystyle \overline{f}|_{\mathbb{A}} = f $. 
\end{prop}
\begin{proof}
Tenemos que ver que $\displaystyle \overline{f} $ es una homografía y que $\displaystyle \overline{f}|_{\mathbb{A}} = f $. Ponemos 
\[\hat{f} : \K^{n+1} \to \K^{n+1} : \left(x_{0}, \ldots, x_{n}\right) \to x_{0}\left(1,f\left(0, \ldots, 0\right)\right) + \left(0, \vec{f}\left(x_{1}, \ldots, x_{n}\right)\right) .\]
Veamos que es lineal. Tenemos que
\[
\begin{split}
	\hat{f}\left(\left(x_{0}, \ldots, x_{n}\right) + \left(y_{0}, \ldots, y_{n}\right)\right) = & \hat{f}\left(\left(x_{0}+y_{0}, \ldots, x_{n}+y_{n}\right)\right) \\
	= & \left(x_{0}+y_{0}\right)\left(1, f\left(0, \ldots, 0\right)\right) + \left(0, \vec{f}\left(x_{1}+y_{1}, \ldots, x_{n}+y_{n}\right)\right) \\
	= & \left(x_{0}+y_{0}\right)\left(1, f\left(0, \ldots, 0\right)\right) + \left(0, \vec{f}\left(x_{1}, \ldots, x_{n}\right)\right)+\left(0, \vec{f}\left(y_{1}, \ldots, y_{n}\right)\right) \\
	= & \left[x_{0}\left(1, f\left(0, \ldots, 0\right)\right) + \left(0, \vec{f}\left(x_{1}, \ldots, x_{n}\right)\right)\right] \\
	+ &  \left[y_{0}\left(1, f\left(0, \ldots, 0\right)\right) + \left(0, \vec{f}\left(y_{1}, \ldots, y_{n}\right)\right)\right] \\
	= & \hat{f}\left(x_{0}, \ldots, x_{n}\right) + \hat{f}\left(y_{0}, \ldots, y_{n}\right) .
\end{split}
\]
Análogamente, si $\displaystyle \lambda \in \K $ tenemos que 
\[
\begin{split}
	\hat{f}\left(\lambda\left(x_{0}, \ldots, x_{n}\right)\right) = & \hat{f}\left(\lambda x_{0}, \ldots, \lambda x_{n}\right) \\
	= & \left(\lambda x_{0}\right)\left(1, f\left(0, \ldots, 0\right)\right) + \left(0, \vec{f}\left(\lambda x_{1}, \ldots, \lambda x_{n}\right)\right) \\
	= & \left(\lambda x_{0}\right)\left(1, f\left(0, \ldots, 0\right)\right) + \lambda\left(0, \vec{f}\left(\lambda x_{1}, \ldots, \lambda x_{n}\right)\right) \\
	= & \lambda \left(x_{0}\left(1, f\left(0, \ldots, 0\right)\right) + \left(0, \vec{f}\left(x_{1}, \ldots, x_{n}\right)\right)\right) \\
	= & \lambda \hat{f}\left(x_{0}, \ldots, x_{n}\right).
\end{split}
\]
Veamos ahora que $\displaystyle \overline{f}|_{i\left(\mathbb{A}\right)} = i \circ f $. Por el teorema anterior sabemos que $\displaystyle \overline{f}|_{i\left(\mathbb{A}\right)} $ es una afinidad. En efecto, tenemos que $\displaystyle \overline{f}\left( \left\{ x_{0} = 0\right\} \right) = \left\{ x_{0} = 0\right\}  $: 
\[
\begin{split}
	\overline{f}\left( \left\{ x_{0} = 0\right\} \right) = & \left[\hat{f}\left( \left\{ x_{0}= 0\right\} \right)\right] = \left\{ \left[0\left(1, f\left(0, \ldots, 0\right)\right)+\left(0, \vec{f}\left(x_{1}, \ldots,x_{n}\right)\right)\right] \; : \; x_{1}, \ldots, x_{n} \in \K\right\} \\
	= & \left\{ x_{0} = 0\right\}  .
\end{split}
\]
Finalmente, para ver que las dos funciones coinciden es suficiente con comprobar la igualdad en una referencia afín. Consideremos la referencia
\[\mathcal{R}_{A} = \left\{ O, O +v_{1}, \ldots, O + v_{n}\right\} .\]
Tenemos que  
\[\overline{f}\left(i\left(O\right)\right) = \overline{f}\left( [1 : 0 : \cdots : 0]\right) = \left[\left(1, f\left(0, \ldots, 0\right)\right)\right]  .\]
Además, $\displaystyle i\left(f\left(O\right)\right) = i\left(f\left(0, \ldots, 0\right)\right) = [\left(1, f\left(0, \ldots, 0\right)\right)] $. De forma análoga, tenemos que si $\displaystyle j = 1, \ldots, n $, 
\[
\begin{split}
	\overline{f}\left(i\left(O +v_{j}\right)\right) = & \overline{f}\left(\left[1: 0 : \cdots : 1 : \cdots : 0\right] \right) \\
	= & \left[1 \left(1, f\left(0, \ldots, 0\right)\right) + \left(0, \vec{f}\left(0, \ldots, 1, \ldots, 0\right)\right)\right] \\
	= & \left[\left(1, f \left(0, \ldots, 0\right) + \vec{f}\left(0, \ldots, 1, \ldots, 0\right)\right)\right] \\
	= & \left[\left(1, f\left(O + v_{j}\right)\right)\right]  .
\end{split}
\]
Por otro lado, 
\[i\left(f\left(O + v_{j}\right)\right) = \left[1, f\left(O +v_{j}\right)\right] .\]
Como son dos afinidades que coinciden en una referencia afín, tendremos que $\displaystyle \overline{f}|_{i\left(\mathbb{A}\right)} = i\circ f $.
\end{proof}
\begin{observation}
 Se puede comprobar que si $\displaystyle \mathcal{E} $ es la referencia estándar de $\displaystyle \mathbb{P}^{n} $, entonces
\[\left[M_{\mathcal{E}}\left(\overline{f}\right)\right] = \left[M_{\mathcal{R}_{C}}\left(f\right)\right]  .\]
\end{observation}
\begin{eg}
Consideremos la aplicación 
\[f: \R^{2} \to \R^{2} : \left(x_{1}, x_{2}\right) \to \left(2x_{1}+x_{2}, 2x_{2}+1\right) .\]
Tendremos que 
\[
\begin{split}
	\overline{f}\left([x_{0}:x_{1}:x_{2}]\right) = & \left[x_{0}\left(1, f\left(0,0\right)\right)+\left(0,\vec{f}\left(x_{1}, x_{2}\right)\right)\right] \\
	= & \left[x_{0}\left(1,0,1\right)+\left(0,2x_{1}+x_{2}, x_{2}\right)\right] \\
	= & \left[x_{0} : 2x_{1}+x_{2}:x_{0}+2x_{2}\right]  .
\end{split}
\]
\end{eg}
Sea $\displaystyle f : \K^{n+1} \to \K $ una forma lineal y $\displaystyle \mathbb{A} = \mathbb{P}^{n}/\mathbb{P}\left( \Ker\left(f\right)\right) $, donde $\displaystyle \mathbb{P}^{n} = \mathbb{P}\left(\K^{n+1}\right) $, es un espacio afín. Si $\displaystyle X \subset \mathbb{A} $ es una variedad afín de dimensión $\displaystyle d $, $\displaystyle X $ viene dado por $\displaystyle n-d $ ecuaciones implícitas. Como $\displaystyle X $ es un espacio afín tiene una referencia afín $\displaystyle \left\{ P_{0}, \ldots, P_{d}\right\}  $ y
\[\overline{X} = V_{\mathbb{P}}\left(P_{0}, \ldots, P_{d}\right) ,\]
es el completado proyectivo de $\displaystyle X $. 
\begin{lema}
Si $\displaystyle P_{0}, \ldots, P_{d} $ son independientes en $\displaystyle \mathbb{A} $, entonces están en posición general en $\displaystyle \mathbb{P}^{n} $.
\end{lema}
\begin{proof}
	Supongamos que $\displaystyle P_{0}, \ldots, P_{d} $ son independientes, por lo que $\displaystyle \left\{ \overrightarrow{P_{0}P_{1}}, \ldots, \overrightarrow{P_{0}P_{d}}\right\}  $ son linealmente independientes. Supongamos que $\displaystyle P_{i} = [v_{i}] $ para $\displaystyle i = 0, \ldots, d $. Tenemos que ver que $\displaystyle \left\{ v_{0}, \ldots, v_{d}\right\}  $ son linealmente independientes. Recordamos que 
	\[\overrightarrow{P_{0}P_{i}} = \frac{v_{i}}{f\left(v_{i}\right)}-\frac{v_{0}}{f\left(v_{0}\right)} .\]
Supongamos que 
\[0 = \lambda_{0}v_{0} + \cdots + \lambda_{d}v_{d} .\]
Así, tenemos que 
\[0 = \lambda_{0}v_{0} + \sum^{d}_{i = 1}\lambda_{i}f\left(v_{i}\right)\left(\overrightarrow{P_{0}P_{i}}+\frac{v_{0}}{f\left(v_{0}\right)}\right) = \left(\lambda_{0}+\sum^{d}_{i = 1}\lambda_{i}\frac{f\left(v_{i}\right)}{f\left(v_{0}\right)}\right)v_{0}+\sum^{d}_{i = 1}\lambda_{i}f\left(v_{i}\right)\overrightarrow{P_{0}P_{i}}.\]
Como $\displaystyle [v_{0}] = P_{0} \in \mathbb{A} = \mathbb{P}^{n} / \mathbb{P}\left(\Ker\left(f\right)\right)  $ y $\displaystyle \overrightarrow{P_{0}P_{i}} \in \Ker\left(f\right) $, tenemos que 
\[f\left(\mu_{0}v_{0}\right) = f\left(\sum^{d}_{i = 1}\mu_{i}\overrightarrow{P_{0}P_{i}}\right) = 0\Rightarrow \mu_{0} = 0 .\]
Por tanto, 
\[\mu_{0}v_{0} = \sum^{d}_{i = 1}\mu_{i}\overrightarrow{P_{0}P_{i}} = 0 .\]
Como $\displaystyle \left\{ \overrightarrow{P_{0}P_{1}}, \ldots, \overrightarrow{P_{0}P_{d}}\right\}  $ son linealmente independientes tenemos que $\displaystyle \mu_{i} = 0 $, por lo que $\displaystyle \lambda f\left(v_{i}\right) = 0 $ y $\displaystyle \lambda_{i} = 0 $. Así, tenemos que 
\[0 = \lambda_{0}v_{0} \Rightarrow \lambda_{0} = 0 .\]
Por tanto, $\displaystyle \left\{ v_{0}, \ldots, v_{d}\right\}  $ son linealmente independientes. 
\end{proof}
\begin{observation}
Por el lema, tenemos que  
\[ \dim\overline{X} = \dim \hat{X} - 1 = \dim\left(L\left( \left\{ v_{0}, \ldots, v_{d}\right\} \right)\right)-1 = d.\]
En particular, $\displaystyle \overline{X} $ está definido por $\displaystyle n-d $ ecuaciones implícitas. Así, si 
\[X = 
\begin{cases}
a_{00}x_{0} + \cdots + a_{0n}x_{n} = c_{0} \\ 
\vdots \\ 
a_{n-d-1,0}x_{0} + \cdots + a_{n-d-1,n}x_{n} = c_{n}
\end{cases}
,\]
y 
\[f\left(x_{0}, \ldots, x_{n}\right) = b_{0}x_{0} + \cdots + b_{n}x_{n} ,\]
suponiendo que $\displaystyle b_{0} \neq 0 $, tenemos que 
\[\mathbb{A} = \left\{ \left[x_{0} : \cdots : x_{n}\right] \; : \; b_{0}x_{0} + \cdots + b_{n}x_{n} = 1\right\}  .\]
Comprobamos que $\displaystyle P_{0}, \ldots, P_{d} $ vistos como puntos de $\displaystyle \mathbb{P}^{n} $ cumplen 
\[
\begin{cases}
a_{00}x_{0} + \cdots + a_{0n}x_{n} = c_{0}\left(b_{0}x_{0} + \cdots + b_{n}x_{n}\right) \\ 
\vdots \\
a_{n-d-1, 0}x_{0} + \cdots + a_{n-d-1,1}x_{n} = c_{n}\left(b_{0}x_{0} + \cdots + b_{n}x_{n}\right)
\end{cases}
.\]
Son $\displaystyle n-d $ ecuaciones implícitas por lo que necesariamente debe ser las ecuaciones de $\displaystyle \overline{X} $.
\end{observation}
\begin{eg}
Consideremos la variedad afín
\[X =
\begin{cases}
2x_{1} + 3x_{2} -x_{3} = 2 \\ 
x_{1} + x_{3} = 1
\end{cases}
,\]
con $\displaystyle X \subset \R^{3} $, que es una recta. Podemos meter $\displaystyle \R^{3} $ en $\displaystyle \mathbb{P}^{3} $ de la forma:
\[\R^{3} \to \mathbb{P}^{3} : \left(x_{1}, x_{2}, x_{3}\right) \to \left[1 : x_{1} : x_{2} : x_{3}\right]  ,\]
es decir, identificamos $\displaystyle \R^{3} $ con $\displaystyle \mathbb{P}^{3}/ \left\{ x_{0} = 0\right\}  $. Así, tendremos que 
\[\overline{X} = 
\begin{cases}
2x_{1}+3x_{2}-x_{3} = 2x_{0} \\ 
x_{1} + x_{3} = x_{0}
\end{cases}
.\]
\end{eg}
\begin{observation}
Sea $\displaystyle \overline{X} $ la completación proyectiva de una variedad afín $\displaystyle X $. Podemos considerar
\[X_{\infty} = \overline{X}/X =  \overline{X} \cap \mathbb{P}\left(\Ker\left(f\right)\right)\quad \text{y} \quad \hat{X}_{\infty}  = \overrightarrow{X},\]
que es una variedad de $\displaystyle \mathbb{P}^{n} $. 
En efecto, si $\displaystyle X = V_{\mathbb{A}}\left(P_{0}, \ldots, P_{d}\right) $ y $\displaystyle \overline{X} = V_{\mathbb{P}}\left(P_{0}, \ldots, P_{d}\right) $, tenemos que $\displaystyle \left[\overrightarrow{P_{0}P_{i}}\right] \in \overline{X} $ y como $\displaystyle f\left(\overrightarrow{P_{0}P_{i}}\right) = 0 $ tenemos que $\displaystyle \left[\overrightarrow{P_{0}P_{i}}\right] \not\in X $. 
Como 
\[\overrightarrow{X} = L\left( \left\{ \overrightarrow{P_{0}P_{1}}, \ldots, \overrightarrow{P_{0}P_{d}}\right\} \right)\subset \hat{X}_{\infty} ,\]
y 
\[\dim \overrightarrow{X} = d \leq \dim\widehat{\overline{X}/X} < d + 1 .\]
Por tanto, debe ser que $\displaystyle \overrightarrow{X} = \widehat{\overline{X}/X} = \hat{X}_{\infty} $. 
\end{observation}

